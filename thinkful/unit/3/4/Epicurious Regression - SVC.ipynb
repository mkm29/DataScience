{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T14:00:49.032887Z",
     "start_time": "2019-01-02T14:00:47.488035Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T14:16:25.345922Z",
     "start_time": "2019-01-02T14:16:23.147323Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('epi_r.csv')\n",
    "z = {0.0: 0, 1.25: 1, 1.875: 2, 2.5: 3, 3.125: 4, 3.75: 5, 4.375: 6, 5.0: 7}\n",
    "z_inv = {v: k for k, v in z.items()}\n",
    "raw_data[\"rating_cat\"] = raw_data.rating.map(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T14:01:42.450857Z",
     "start_time": "2019-01-02T14:01:42.441536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.375    8019\n",
       "3.750    5169\n",
       "5.000    2719\n",
       "0.000    1836\n",
       "3.125    1489\n",
       "2.500     532\n",
       "1.250     164\n",
       "1.875     124\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First lets look at the ratings.\n",
    "raw_data.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T14:02:03.065623Z",
     "start_time": "2019-01-02T14:02:03.059860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    8019\n",
       "5    5169\n",
       "7    2719\n",
       "0    1836\n",
       "4    1489\n",
       "3     532\n",
       "1     164\n",
       "2     124\n",
       "Name: rating_cat, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[\"rating_cat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T14:02:18.749886Z",
     "start_time": "2019-01-02T14:02:18.744435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.25 , 0.625, 0.625, 0.625, 0.625, 0.625, 0.625])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(np.array([0.0, 1.25, 1.875, 2.5, 3.125, 3.75, 4.375, 5.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ratings are actually discrete, a classifier makes more sense. Note that the rating levels are not uniformly distributed. \n",
    "\n",
    "First lets add a binary feature to indicate if the recipe lists calories that are in the top 75% of all ratings, as well as some group some highly correlated features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T18:58:25.150005Z",
     "start_time": "2019-01-01T18:58:25.145053Z"
    }
   },
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T14:05:58.073164Z",
     "start_time": "2019-01-02T14:05:57.363727Z"
    }
   },
   "outputs": [],
   "source": [
    "X = raw_data.dropna().drop(['rating', 'title', 'rating_cat'], axis = 1)\n",
    "X_test, X_train, y_test, y_train = train_test_split(X, raw_data.dropna().rating, test_size=0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T14:06:12.114912Z",
     "start_time": "2019-01-02T14:06:04.491790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calories             fat                    0.996224\n",
       "fat                  calories               0.996224\n",
       "sodium               calories               0.996084\n",
       "calories             sodium                 0.996084\n",
       "fat                  sodium                 0.985281\n",
       "sodium               fat                    0.985281\n",
       "peanut free          soy free               0.941935\n",
       "soy free             peanut free            0.941935\n",
       "kosher               pescatarian            0.884051\n",
       "pescatarian          kosher                 0.884051\n",
       "portland             oregon                 0.880571\n",
       "oregon               portland               0.880571\n",
       "drink                alcoholic              0.858857\n",
       "alcoholic            drink                  0.858857\n",
       "tree nut free        peanut free            0.825273\n",
       "peanut free          tree nut free          0.825273\n",
       "tree nut free        soy free               0.798740\n",
       "soy free             tree nut free          0.798740\n",
       "missouri             st. louis              0.745222\n",
       "st. louis            missouri               0.745222\n",
       "pescatarian          vegetarian             0.742579\n",
       "vegetarian           pescatarian            0.742579\n",
       "sodium               protein                0.740284\n",
       "protein              sodium                 0.740284\n",
       "vegetarian           kosher                 0.739058\n",
       "kosher               vegetarian             0.739058\n",
       "pescatarian          soy free               0.737849\n",
       "soy free             pescatarian            0.737849\n",
       "pescatarian          peanut free            0.737603\n",
       "peanut free          pescatarian            0.737603\n",
       "kosher               peanut free            0.735095\n",
       "peanut free          kosher                 0.735095\n",
       "protein              calories               0.733534\n",
       "calories             protein                0.733534\n",
       "kosher               soy free               0.731291\n",
       "soy free             kosher                 0.731291\n",
       "breakfast            brunch                 0.716724\n",
       "brunch               breakfast              0.716724\n",
       "macaroni and cheese  cookbooks              0.707075\n",
       "cookbooks            macaroni and cheese    0.707075\n",
       "louisville           kentucky               0.707075\n",
       "kentucky             louisville             0.707075\n",
       "illinois             chicago                0.707011\n",
       "chicago              illinois               0.707011\n",
       "protein              fat                    0.701079\n",
       "fat                  protein                0.701079\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see what features are extrmely correlated\n",
    "cm = X_train.corr()\n",
    "s = cm.unstack()\n",
    "so = s[s!=1.0].sort_values(kind=\"quicksort\", ascending=False)\n",
    "so[so>=0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T14:12:11.210060Z",
     "start_time": "2019-01-02T14:12:09.101412Z"
    }
   },
   "outputs": [],
   "source": [
    "# combine calories, fat and sodium\n",
    "X_train[\"source\"] = X_train[['fat', 'calories', 'sodium']].sum(axis=1)\n",
    "X_test[\"source\"] = X_test[['fat', 'calories', 'sodium']].sum(axis=1)\n",
    "# features to combine* (binary interaction)\n",
    "features1 = ['calories', 'calories', 'sodium', 'peanut free', \n",
    "             'pescatarian', 'drink', 'peanut free', 'portland', \n",
    "             'soy free', 'sodium', 'vegetarian', 'snack week', \n",
    "             'pescatarian', 'kosher', 'peanut free', 'peanut free', \n",
    "             'soy free', 'calories', 'brunch', 'kentucky', 'denver', \n",
    "             'louisiana', 'new orleans', 'lasagna']\n",
    "\n",
    "features2 = ['sodium', 'fat', 'fat', 'soy free', 'kosher', 'alcoholic', \n",
    "             'tree nut free', 'oregon', 'tree nut free', 'protein', \n",
    "             'pescatarian', 'snack', 'soy free', 'vegetarian', \n",
    "             'pescatarian', 'kosher', 'kosher', 'protein', 'breakfast', \n",
    "             'louisville', 'omelet', 'kitchen olympics', 'louisiana', 'epi loves the microwave']\n",
    "\n",
    "for a,b in zip(features1, features2):\n",
    "    X_train[a + \"_\" + b] = X_train[a] * X_train[b]\n",
    "    X_test[a + \"_\" + b] = X_test[a] * X_test[b]\n",
    "    \n",
    "for b in ['fat', 'calories', 'sodium']:\n",
    "    X_train['protein_' + b] = X_train['protein'] * X_train[b]\n",
    "    X_test['protein_' + b] = X_test['protein'] * X_test[b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection  \n",
    "\n",
    "We will first predict how likely the recipe is a high (>=2.5 rating) or low (<2.5), and given this predicted probability we can feed the data to a further model (2 layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**High or Low rating?** (<= 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T14:31:31.257939Z",
     "start_time": "2019-01-02T14:31:30.947102Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_dummy = pd.get_dummies(X_train)\n",
    "# convert all columns to int's and make source_pc binary\n",
    "X_train_dummy = X_train_dummy.astype(int)\n",
    "\n",
    "# Features & Target\n",
    "y_low = y_train <= 2.5\n",
    "\n",
    "#Pipeline Construction.\n",
    "anova_low = SelectKBest(f_classif, k=30)\n",
    "svc_low = SVC(kernel='linear')\n",
    "anova_svc = make_pipeline(anova_low, svc_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T14:31:38.867020Z",
     "start_time": "2019-01-02T14:31:33.905386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.8856371  0.88878883 0.88383611 0.88473661 0.8865376 ]\n",
      "Cross-Validation Score Averaged Across Folds: 88.59%.\n",
      "\n",
      "Selected Features: ['alcoholic', 'bake', 'bitters', 'bon appétit', 'brandy', 'chartreuse', 'chile pepper', 'cocktail', 'cocktail party', 'condiment', 'créme de cacao', 'drink', 'fall', 'fortified wine', 'gin', 'harpercollins', 'house & garden', 'liqueur', 'non-alcoholic', 'peanut free', 'rum', 'sauté', 'soy free', 'spirit', 'tree nut free', 'vegan', 'weelicious', 'winter', 'peanut free_soy free', 'drink_alcoholic']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting & Cross-Validation.\n",
    "anova_svc.fit(X_train_dummy,y_low)\n",
    "scores_low = cross_val_score(anova_svc, X_train_dummy, y_low, cv=5)\n",
    "\n",
    "#De-Masking Selected Features.\n",
    "features_low = anova_low.get_support(indices=True)\n",
    "selected_features_low = list(X_train_dummy.columns[features_low])\n",
    "\n",
    "#Printing Outcomes.\n",
    "print('Cross-Validation Scores: {}'.format(scores_low))\n",
    "print('Cross-Validation Score Averaged Across Folds: {:.2%}.\\n'.format(scores_low.mean()))\n",
    "print('Selected Features: {}\\n'.format(selected_features_low))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T14:31:58.897237Z",
     "start_time": "2019-01-02T14:31:50.455822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.8865376  0.8865376  0.88518685 0.88743809 0.8865376 ]\n",
      "Cross-Validation Score Averaged Across Folds: 88.64%.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_1ow = SVC()\n",
    "X_low = X_train[selected_features_low]\n",
    "svc_1ow.fit(X_low,y_low)\n",
    "\n",
    "scores_low = cross_val_score(svc_1ow, X_train[selected_features_low], y_low, cv=5)\n",
    "print('Cross-Validation Scores: {}'.format(scores_low))\n",
    "print('Cross-Validation Score Averaged Across Folds: {:.2%}.\\n'.format(scores_low.mean()))\n",
    "y_pred_train = svc_1ow.predict(X_train[selected_features_low]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model simply predicts if the given recipe will be rated high or low. Let's see how it performs on the test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T15:07:14.719163Z",
     "start_time": "2019-01-02T15:07:14.701486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      9765\n",
      "           1       0.83      0.08      0.14      1340\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     11105\n",
      "   macro avg       0.86      0.54      0.54     11105\n",
      "weighted avg       0.88      0.89      0.84     11105\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8868977937865826"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clasification report\n",
    "results_train = metrics.classification_report(y_true=(y_train<=2.5).astype(int), y_pred=y_pred_train)\n",
    "print(results_train)\n",
    "metrics.accuracy_score(y_true=(y_train<=2.5).astype(int), y_pred=y_pred_train)\n",
    "#metrics.auc() HOW TO USE THIS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T15:08:09.426325Z",
     "start_time": "2019-01-02T15:08:08.878470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      4194\n",
      "           1       0.73      0.06      0.12       565\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      4759\n",
      "   macro avg       0.81      0.53      0.53      4759\n",
      "weighted avg       0.87      0.89      0.84      4759\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8861105274217272"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = svc_1ow.predict(X_test[selected_features_low])\n",
    "#Clasification report\n",
    "results_test = metrics.classification_report(y_true=(y_test<=2.5).astype(int), y_pred=y_pred_test)\n",
    "print(results_test)\n",
    "metrics.accuracy_score(y_true=(y_test<=2.5).astype(int), y_pred=y_pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classification task seems quite limited (not practical), so let's open it up to predict each rating level.\n",
    "\n",
    "Let's use LASSO regression to identify features.  \n",
    "\n",
    "## LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T14:45:06.638452Z",
     "start_time": "2019-01-02T14:43:55.220850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>calories</th>\n",
       "      <td>-1.532908e-21</td>\n",
       "      <td>-1.709296e-21</td>\n",
       "      <td>-1.716656e-21</td>\n",
       "      <td>-1.666317e-21</td>\n",
       "      <td>2.226187e-21</td>\n",
       "      <td>-8.858959e-22</td>\n",
       "      <td>2.432812e-22</td>\n",
       "      <td>5.041605e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protein</th>\n",
       "      <td>-6.070384e-23</td>\n",
       "      <td>-6.625873e-23</td>\n",
       "      <td>-6.644454e-23</td>\n",
       "      <td>-6.440107e-23</td>\n",
       "      <td>4.354286e-24</td>\n",
       "      <td>-2.976108e-23</td>\n",
       "      <td>-9.415707e-24</td>\n",
       "      <td>2.926326e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fat</th>\n",
       "      <td>-7.394482e-23</td>\n",
       "      <td>-8.210371e-23</td>\n",
       "      <td>-8.248664e-23</td>\n",
       "      <td>-7.972559e-23</td>\n",
       "      <td>1.401701e-22</td>\n",
       "      <td>-3.525707e-23</td>\n",
       "      <td>3.996477e-23</td>\n",
       "      <td>1.733842e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sodium</th>\n",
       "      <td>-1.620845e-21</td>\n",
       "      <td>-1.928990e-21</td>\n",
       "      <td>-1.935301e-21</td>\n",
       "      <td>-1.860240e-21</td>\n",
       "      <td>2.109248e-21</td>\n",
       "      <td>-7.060088e-22</td>\n",
       "      <td>3.022891e-22</td>\n",
       "      <td>5.639849e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#cakeweek</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.086330e-28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0             1             2             3  \\\n",
       "calories  -1.532908e-21 -1.709296e-21 -1.716656e-21 -1.666317e-21   \n",
       "protein   -6.070384e-23 -6.625873e-23 -6.644454e-23 -6.440107e-23   \n",
       "fat       -7.394482e-23 -8.210371e-23 -8.248664e-23 -7.972559e-23   \n",
       "sodium    -1.620845e-21 -1.928990e-21 -1.935301e-21 -1.860240e-21   \n",
       "#cakeweek  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "\n",
       "                      4             5             6             7  \n",
       "calories   2.226187e-21 -8.858959e-22  2.432812e-22  5.041605e-21  \n",
       "protein    4.354286e-24 -2.976108e-23 -9.415707e-24  2.926326e-22  \n",
       "fat        1.401701e-22 -3.525707e-23  3.996477e-23  1.733842e-22  \n",
       "sodium     2.109248e-21 -7.060088e-22  3.022891e-22  5.639849e-21  \n",
       "#cakeweek  0.000000e+00  7.086330e-28  0.000000e+00  0.000000e+00  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "lassoregr = LogisticRegression(penalty ='l1', solver='saga', multi_class='multinomial')\n",
    "lassoregr.fit(X_train, y_train.map(z))\n",
    "\n",
    "coeffs = pd.DataFrame(lassoregr.coef_.transpose())\n",
    "coeffs.index = X_train.columns\n",
    "coeffs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be easier to visualize if we first converted the above matrix into rankings (along each column). Say we wanted to optimize the model to perform on those recipes with a 3.125 rating, then we take the top k features for the 5th column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T15:13:43.993325Z",
     "start_time": "2019-01-02T15:08:36.929763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['calories_protein', 'protein_calories', 'protein_sodium',\n",
      "       'sodium_protein', 'bon appétit', 'peanut free', 'soy free',\n",
      "       'peanut free_soy free', 'tree nut free', 'peanut free_tree nut free',\n",
      "       'soy free_tree nut free', 'gourmet', 'vegetarian', 'pescatarian',\n",
      "       'bake', 'kosher', 'peanut free_pescatarian', 'peanut free_kosher',\n",
      "       'summer', 'wheat/gluten-free', 'pescatarian_soy free',\n",
      "       'soy free_kosher', 'quick & easy', 'pescatarian_kosher',\n",
      "       'kosher_vegetarian', 'vegetarian_pescatarian', 'dessert', 'fall',\n",
      "       'winter'],\n",
      "      dtype='object')\n",
      "Cross-Validation Scores: [0.47616906 0.46558704 0.46375507 0.47408743 0.46077547]\n",
      "Cross-Validation Score Averaged Across Folds: 46.81%.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.29      0.36       361\n",
      "           1       1.00      0.15      0.26        40\n",
      "           2       0.00      0.00      0.00        31\n",
      "           3       0.80      0.12      0.21       133\n",
      "           4       0.83      0.12      0.21       328\n",
      "           5       0.60      0.12      0.20      1243\n",
      "           6       0.46      0.96      0.62      1976\n",
      "           7       0.69      0.14      0.24       647\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      4759\n",
      "   macro avg       0.61      0.24      0.26      4759\n",
      "weighted avg       0.57      0.48      0.39      4759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_features = coeffs.iloc[:,4].sort_values().index[:29]\n",
    "print(new_features)\n",
    "\n",
    "svc_new = SVC(probability=True)\n",
    "svc_new.fit(X_train[new_features], y_train.map(z))\n",
    "\n",
    "scores_new = cross_val_score(svc_new, X_train[new_features], y_train.map(z), cv=5)\n",
    "print('Cross-Validation Scores: {}'.format(scores_new))\n",
    "print('Cross-Validation Score Averaged Across Folds: {:.2%}.\\n'.format(scores_new.mean()))\n",
    "\n",
    "p_pred_new = svc_new.predict_proba(X_test[new_features])\n",
    "\n",
    "y_pred_new = p_pred_new.argmax(axis=1)\n",
    "#Clasification report\n",
    "results_new = metrics.classification_report(y_true=y_test.map(z), y_pred=y_pred_new)\n",
    "print(results_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa this set of features appears to improve on all classes! Let's see if we can get better model performance from using a random forest to select the same number of features.\n",
    "\n",
    "## Random Forest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T15:16:16.841644Z",
     "start_time": "2019-01-02T15:16:15.891557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['calories', 'source', 'calories_sodium', 'sodium_protein', 'calories_protein', 'sodium', 'calories_fat', 'protein_sodium', 'protein_calories', 'sodium_fat', 'fat', 'protein_fat', 'protein', 'bon appétit', 'summer', 'gourmet', 'quick & easy', 'winter', 'bake', 'onion', 'fall', 'vegetarian', 'spring', 'tomato', 'vegetable', 'wheat/gluten-free', 'herb', 'milk/cream', 'egg', 'soy free_tree nut free']\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "X_train2 = pd.get_dummies(X_train.dropna())\n",
    "rfc.fit(X_train2, y_train.map(z))\n",
    "feats = pd.DataFrame(X_train2.columns, rfc.feature_importances_)\n",
    "feats.reset_index(inplace=True)\n",
    "features = list(feats.sort_values(by='index', ascending=False).iloc[:30, 1])\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T15:25:46.512010Z",
     "start_time": "2019-01-02T15:25:46.508524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.29      0.36       361\n",
      "           1       1.00      0.15      0.26        40\n",
      "           2       0.00      0.00      0.00        31\n",
      "           3       0.80      0.12      0.21       133\n",
      "           4       0.83      0.12      0.21       328\n",
      "           5       0.60      0.12      0.20      1243\n",
      "           6       0.46      0.96      0.62      1976\n",
      "           7       0.69      0.14      0.24       647\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      4759\n",
      "   macro avg       0.61      0.24      0.26      4759\n",
      "weighted avg       0.57      0.48      0.39      4759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T15:18:52.287134Z",
     "start_time": "2019-01-02T15:17:40.004812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.18      0.29       361\n",
      "           1       1.00      0.17      0.30        40\n",
      "           2       0.80      0.13      0.22        31\n",
      "           3       0.86      0.14      0.23       133\n",
      "           4       0.98      0.13      0.23       328\n",
      "           5       0.91      0.11      0.20      1243\n",
      "           6       0.45      0.99      0.62      1976\n",
      "           7       0.80      0.16      0.27       647\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      4759\n",
      "   macro avg       0.82      0.25      0.29      4759\n",
      "weighted avg       0.70      0.49      0.39      4759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now use an SVC for classifying recipes, using only the above features\n",
    "svc = SVC(probability=True)\n",
    "svc.fit(X_train[features], y_train.map(z))\n",
    "p_pred = svc.predict_proba(X_test[features])\n",
    "y_pred_test = p_pred.argmax(axis=1)\n",
    "#Clasification report\n",
    "results = metrics.classification_report(y_true=y_test.map(z), y_pred=y_pred_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T15:25:23.104226Z",
     "start_time": "2019-01-02T15:25:23.052206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>278</td>\n",
       "      <td>14</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>283</td>\n",
       "      <td>2</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>1094</td>\n",
       "      <td>4</td>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1959</td>\n",
       "      <td>4</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>536</td>\n",
       "      <td>106</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>83</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>43</td>\n",
       "      <td>151</td>\n",
       "      <td>4317</td>\n",
       "      <td>132</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0  1  2   3   4    5     6    7   All\n",
       "rating                                        \n",
       "0       64  0  0   1   1    3   278   14   361\n",
       "1        1  7  0   0   0    0    31    1    40\n",
       "2        2  0  4   0   0    0    25    0    31\n",
       "3        2  0  0  18   0    1   111    1   133\n",
       "4        0  0  0   0  42    1   283    2   328\n",
       "5        7  0  0   1   0  137  1094    4  1243\n",
       "6        3  0  1   1   0    8  1959    4  1976\n",
       "7        4  0  0   0   0    1   536  106   647\n",
       "All     83  7  5  21  43  151  4317  132  4759"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy tables.\n",
    "table_test = pd.crosstab(y_test.map(z), y_pred_test, margins=True)\n",
    "table_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion  \n",
    "\n",
    "The model built from features selected by LASSO regression made drastic improvements over the naive SVR model (using all features), and using a Random Forest to select the features resulted in the best performing model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
