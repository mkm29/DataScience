{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T03:02:02.628474Z",
     "start_time": "2019-01-02T03:02:02.621247Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boost guided example\n",
    "\n",
    "Having walked through gradient boost by hand, now let's try it with SKlearn.  We'll still use the European Social Survey Data, but now with a categorical outcome: Whether or not someone lives with a partner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T01:51:39.700122Z",
     "start_time": "2019-01-02T01:51:37.502251Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
    "\n",
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're now working with a binary outcome, we've switched to a classifier.  Now our loss function can't be the residuals.  Our options are \"deviance\", or \"exponential\".  Deviance is used for logistic regression, and we'll try that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T01:51:48.768383Z",
     "start_time": "2019-01-02T01:51:47.221890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04650845608292417\n",
      "Percent Type II errors: 0.17607746863066012\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06257668711656442\n",
      "Percent Type II errors: 0.18527607361963191\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike decision trees, gradient boost solutions are not terribly easy to interpret on the surface.  But they aren't quite a black box.  We can get a measure of how important various features are by counting how many times a feature is used over the course of many decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T01:51:53.094620Z",
     "start_time": "2019-01-02T01:51:52.852664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that age and happiness are the most important features in predicting whether or not someone lives with a partner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### DRILL: Improve this gradient boost model\n",
    "\n",
    "While this model is already doing alright, we've seen from the Type I and Type II error rates that there is definitely room for improvement.  Your task is to see how low you can get the error rates to go in the test set, based on your model in the training set.  Strategies you might use include:\n",
    "\n",
    "* Creating new features\n",
    "* Applying more overfitting-prevention strategies like subsampling\n",
    "* More iterations\n",
    "* Trying a different loss function\n",
    "* Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications\n",
    "\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T01:53:23.955633Z",
     "start_time": "2019-01-02T01:53:23.936664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idno</th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partner</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>47687.771195</td>\n",
       "      <td>6.492918</td>\n",
       "      <td>3.864353</td>\n",
       "      <td>5.635149</td>\n",
       "      <td>6.062238</td>\n",
       "      <td>5.359266</td>\n",
       "      <td>7.905845</td>\n",
       "      <td>5.030521</td>\n",
       "      <td>2.747856</td>\n",
       "      <td>1.482944</td>\n",
       "      <td>50.979254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>28291.068283</td>\n",
       "      <td>6.512125</td>\n",
       "      <td>3.745373</td>\n",
       "      <td>5.478622</td>\n",
       "      <td>5.913848</td>\n",
       "      <td>5.261008</td>\n",
       "      <td>7.392789</td>\n",
       "      <td>5.512444</td>\n",
       "      <td>2.768985</td>\n",
       "      <td>1.517869</td>\n",
       "      <td>41.316528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 idno      year     tvtot   ppltrst   pplfair    pplhlp  \\\n",
       "partner                                                                   \n",
       "1.0      47687.771195  6.492918  3.864353  5.635149  6.062238  5.359266   \n",
       "2.0      28291.068283  6.512125  3.745373  5.478622  5.913848  5.261008   \n",
       "\n",
       "            happy   sclmeet    sclact      gndr       agea  \n",
       "partner                                                     \n",
       "1.0      7.905845  5.030521  2.747856  1.482944  50.979254  \n",
       "2.0      7.392789  5.512444  2.768985  1.517869  41.316528  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"partner\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T02:05:54.865246Z",
     "start_time": "2019-01-02T02:05:54.855558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sclmeet</th>\n",
       "      <td>0.250375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>0.230598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE</th>\n",
       "      <td>0.186157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gndr</th>\n",
       "      <td>0.155462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.148420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CZ</th>\n",
       "      <td>0.090150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO</th>\n",
       "      <td>0.041529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pplhlp</th>\n",
       "      <td>0.030669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agea</th>\n",
       "      <td>0.029404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppltrst</th>\n",
       "      <td>0.024485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>0.023745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tvtot</th>\n",
       "      <td>0.020486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES</th>\n",
       "      <td>0.018718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sclact</th>\n",
       "      <td>0.013290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH</th>\n",
       "      <td>0.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pplfair</th>\n",
       "      <td>0.008377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "sclmeet  0.250375\n",
       "happy    0.230598\n",
       "SE       0.186157\n",
       "gndr     0.155462\n",
       "year     0.148420\n",
       "CZ       0.090150\n",
       "NO       0.041529\n",
       "pplhlp   0.030669\n",
       "agea     0.029404\n",
       "ppltrst  0.024485\n",
       "DE       0.023745\n",
       "tvtot    0.020486\n",
       "ES       0.018718\n",
       "sclact   0.013290\n",
       "CH       0.010300\n",
       "pplfair  0.008377"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We saw the best results last time when using LASSO regression to select features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lassoregr = LogisticRegression(penalty ='l1', solver='liblinear')\n",
    "lassoregr.fit(X_train, y_train)\n",
    "\n",
    "coeffs = pd.DataFrame(lassoregr.coef_.transpose())\n",
    "coeffs.index = X_train.columns\n",
    "np.abs(coeffs).sort_values(by=0, ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T03:03:41.776562Z",
     "start_time": "2019-01-02T03:03:41.514097Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04091653027823241\n",
      "Percent Type II errors: 0.2043098745226405\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.05644171779141104\n",
      "Percent Type II errors: 0.21104294478527608\n"
     ]
    }
   ],
   "source": [
    "selected_features1 = list(np.abs(coeffs).sort_values(by=0, ascending = False).index[:10])\n",
    "selected_features2 = list(set(selected_features).union(set(selected_features1)))\n",
    "\n",
    "# We'll make 20 iterations, use 8-deep trees, and set our loss function.\n",
    "\n",
    "params = {'n_estimators': 20,\n",
    "          'max_depth': 8,\n",
    "          'learning_rate': 0.07,\n",
    "          'min_samples_split': 0.1,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train[selected_features2], y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train[selected_features2])\n",
    "predict_test = clf.predict(X_test[selected_features2])\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T03:04:31.031899Z",
     "start_time": "2019-01-02T03:04:31.023643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.91      0.81       505\n",
      "         1.0       0.75      0.45      0.56       310\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       815\n",
      "   macro avg       0.74      0.68      0.68       815\n",
      "weighted avg       0.74      0.73      0.71       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = metrics.classification_report(y_true=y_test, y_pred=predict_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets engineer some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T03:09:28.263434Z",
     "start_time": "2019-01-02T03:09:28.249977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ppltrst  pplfair    0.595645\n",
       "pplfair  ppltrst    0.595645\n",
       "dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see what features are extrmely correlated\n",
    "cm = X_train.corr()\n",
    "s = cm.unstack()\n",
    "so = s[s!=1.0].sort_values(kind=\"quicksort\", ascending=False)\n",
    "so[so>=0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T03:24:47.047326Z",
     "start_time": "2019-01-02T03:24:46.975714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>CH</th>\n",
       "      <th>CZ</th>\n",
       "      <th>DE</th>\n",
       "      <th>ES</th>\n",
       "      <th>NO</th>\n",
       "      <th>SE</th>\n",
       "      <th>agea_group</th>\n",
       "      <th>ppltrst_pplfair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "      <td>7332.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.444763</td>\n",
       "      <td>3.855837</td>\n",
       "      <td>5.496590</td>\n",
       "      <td>5.915166</td>\n",
       "      <td>5.242771</td>\n",
       "      <td>7.682488</td>\n",
       "      <td>5.188216</td>\n",
       "      <td>2.740998</td>\n",
       "      <td>1.498363</td>\n",
       "      <td>47.272095</td>\n",
       "      <td>0.201173</td>\n",
       "      <td>0.164621</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>0.312602</td>\n",
       "      <td>0.193672</td>\n",
       "      <td>0.124250</td>\n",
       "      <td>1.338516</td>\n",
       "      <td>35.343017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.496973</td>\n",
       "      <td>2.020783</td>\n",
       "      <td>2.225058</td>\n",
       "      <td>2.135412</td>\n",
       "      <td>2.189366</td>\n",
       "      <td>1.750376</td>\n",
       "      <td>1.444856</td>\n",
       "      <td>0.905820</td>\n",
       "      <td>0.500031</td>\n",
       "      <td>18.313567</td>\n",
       "      <td>0.400904</td>\n",
       "      <td>0.370863</td>\n",
       "      <td>0.060576</td>\n",
       "      <td>0.463585</td>\n",
       "      <td>0.395201</td>\n",
       "      <td>0.329889</td>\n",
       "      <td>1.043705</td>\n",
       "      <td>21.360972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year        tvtot      ppltrst      pplfair       pplhlp  \\\n",
       "count  7332.000000  7332.000000  7332.000000  7332.000000  7332.000000   \n",
       "mean      6.444763     3.855837     5.496590     5.915166     5.242771   \n",
       "std       0.496973     2.020783     2.225058     2.135412     2.189366   \n",
       "min       6.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       6.000000     2.000000     4.000000     5.000000     4.000000   \n",
       "50%       6.000000     4.000000     6.000000     6.000000     5.000000   \n",
       "75%       7.000000     5.000000     7.000000     8.000000     7.000000   \n",
       "max       7.000000     7.000000    10.000000    10.000000    10.000000   \n",
       "\n",
       "             happy      sclmeet       sclact         gndr         agea  \\\n",
       "count  7332.000000  7332.000000  7332.000000  7332.000000  7332.000000   \n",
       "mean      7.682488     5.188216     2.740998     1.498363    47.272095   \n",
       "std       1.750376     1.444856     0.905820     0.500031    18.313567   \n",
       "min       0.000000     1.000000     1.000000     1.000000    15.000000   \n",
       "25%       7.000000     4.000000     2.000000     1.000000    33.000000   \n",
       "50%       8.000000     6.000000     3.000000     1.000000    47.000000   \n",
       "75%       9.000000     6.000000     3.000000     2.000000    61.000000   \n",
       "max      10.000000     7.000000     5.000000     2.000000   103.000000   \n",
       "\n",
       "                CH           CZ           DE           ES           NO  \\\n",
       "count  7332.000000  7332.000000  7332.000000  7332.000000  7332.000000   \n",
       "mean      0.201173     0.164621     0.003682     0.312602     0.193672   \n",
       "std       0.400904     0.370863     0.060576     0.463585     0.395201   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                SE   agea_group  ppltrst_pplfair  \n",
       "count  7332.000000  7332.000000      7332.000000  \n",
       "mean      0.124250     1.338516        35.343017  \n",
       "std       0.329889     1.043705        21.360972  \n",
       "min       0.000000     0.000000         0.000000  \n",
       "25%       0.000000     0.000000        20.000000  \n",
       "50%       0.000000     1.000000        35.000000  \n",
       "75%       0.000000     2.000000        49.000000  \n",
       "max       1.000000     4.000000       100.000000  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T03:19:56.789409Z",
     "start_time": "2019-01-02T03:19:56.785839Z"
    }
   },
   "outputs": [],
   "source": [
    "# (50, 68], (0, 33], (68, 85], (33, 50], (85, 103]\n",
    "def agea_group(x):\n",
    "    if x <= 33:\n",
    "        return 0\n",
    "    if x <= 50:\n",
    "        return 1\n",
    "    if x <= 68:\n",
    "        return 2\n",
    "    if x <= 85:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T03:21:49.680292Z",
     "start_time": "2019-01-02T03:21:49.595381Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mitchellmurphy/anaconda3/envs/python3.5/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/mitchellmurphy/anaconda3/envs/python3.5/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Bing agea\n",
    "X_train[\"agea_group\"] = X_train.agea.apply(agea_group)\n",
    "X_test[\"agea_group\"] = X_test.agea.apply(agea_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T03:30:47.828331Z",
     "start_time": "2019-01-02T03:30:47.681686Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mitchellmurphy/anaconda3/envs/python3.5/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/mitchellmurphy/anaconda3/envs/python3.5/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/mitchellmurphy/anaconda3/envs/python3.5/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Users/mitchellmurphy/anaconda3/envs/python3.5/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# create an interaction between ppltrst and pplfair\n",
    "X_train[\"ppltrst_pplfair\"] = X_train[\"ppltrst\"] * X_train[\"pplfair\"]\n",
    "X_test[\"ppltrst_pplfair\"] = X_test[\"ppltrst\"] * X_test[\"pplfair\"]\n",
    "# Year can just be binary\n",
    "X_train[\"year6\"] = (X_train.year == 6.0).astype(int)\n",
    "X_test[\"year6\"] = (X_test.year == 6.0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T03:32:54.265194Z",
     "start_time": "2019-01-02T03:32:54.029250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>agea_group</th>\n",
       "      <td>0.593270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sclmeet</th>\n",
       "      <td>0.252973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>0.231370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE</th>\n",
       "      <td>0.222907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.164951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gndr</th>\n",
       "      <td>0.161276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CZ</th>\n",
       "      <td>0.121182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agea</th>\n",
       "      <td>0.061710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pplfair</th>\n",
       "      <td>0.051063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pplhlp</th>\n",
       "      <td>0.026958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH</th>\n",
       "      <td>0.026739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppltrst</th>\n",
       "      <td>0.026208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>0.019963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tvtot</th>\n",
       "      <td>0.019352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sclact</th>\n",
       "      <td>0.014309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppltrst_pplfair</th>\n",
       "      <td>0.008635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year6</th>\n",
       "      <td>0.001736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO</th>\n",
       "      <td>0.001466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "agea_group       0.593270\n",
       "sclmeet          0.252973\n",
       "happy            0.231370\n",
       "SE               0.222907\n",
       "year             0.164951\n",
       "gndr             0.161276\n",
       "CZ               0.121182\n",
       "agea             0.061710\n",
       "pplfair          0.051063\n",
       "pplhlp           0.026958\n",
       "CH               0.026739\n",
       "ppltrst          0.026208\n",
       "DE               0.019963\n",
       "tvtot            0.019352\n",
       "sclact           0.014309\n",
       "ppltrst_pplfair  0.008635\n",
       "year6            0.001736\n",
       "NO               0.001466\n",
       "ES               0.000000"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We saw the best results last time when using LASSO regression to select features\n",
    "lassoregr = LogisticRegression(penalty ='l1', solver='liblinear')\n",
    "lassoregr.fit(X_train, y_train)\n",
    "\n",
    "coeffs = pd.DataFrame(lassoregr.coef_.transpose())\n",
    "coeffs.index = X_train.columns\n",
    "np.abs(coeffs).sort_values(by=0, ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T03:37:53.456690Z",
     "start_time": "2019-01-02T03:37:53.070250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.011729405346426624\n",
      "Percent Type II errors: 0.1782596835788325\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06012269938650307\n",
      "Percent Type II errors: 0.21595092024539878\n"
     ]
    }
   ],
   "source": [
    "selected_features1 = list(np.abs(coeffs).sort_values(by=0, ascending = False).index[:14])\n",
    "\n",
    "# We'll make 20 iterations, use 8-deep trees, and set our loss function.\n",
    "\n",
    "params = {'n_estimators': 10,\n",
    "          'max_depth': 8,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train[selected_features1], y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train[selected_features1])\n",
    "predict_test = clf.predict(X_test[selected_features1])\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T03:38:39.265121Z",
     "start_time": "2019-01-02T03:38:39.257613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.90      0.80       505\n",
      "         1.0       0.73      0.43      0.54       310\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       815\n",
      "   macro avg       0.73      0.67      0.67       815\n",
      "weighted avg       0.73      0.72      0.70       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results2 = metrics.classification_report(y_true=y_test, y_pred=predict_test)\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much of a difference when adding these features."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "59px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
