{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T23:27:56.352112Z",
     "start_time": "2019-03-01T23:27:52.773248Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import stopwords, state_union\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction  \n",
    "\n",
    "In this challenge, I want to build a model to classify state of the union addresses. In this case I will only be concerned with two previous presidents: Ronald Reagan and Bill Clinton; given a single sentence can we predict which president said it? This project will involve 5 primary steps:\n",
    "\n",
    "  1. Data cleaning / processing / language parsing\n",
    "  2. Create features using two different NLP methods: For example, BoW vs tf-idf.\n",
    "  3. Use the features to fit supervised learning models for each feature set to predict the category outcomes.\n",
    "  4. Assess your models using cross-validation and determine whether one model performed better.\n",
    "  5. Pick one of the models and try to increase accuracy by at least 5 percentage points.\n",
    "  \n",
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:13:32.011416Z",
     "start_time": "2019-03-01T21:13:31.998530Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1.  Get all Reagan transcripts\n",
    "reagan_text = \"\"\n",
    "files = ['1981-Reagan.txt', '1982-Reagan.txt',\n",
    "         '1983-Reagan.txt','1984-Reagan.txt',\n",
    "         '1985-Reagan.txt','1986-Reagan.txt',\n",
    "         '1987-Reagan.txt','1988-Reagan.txt']\n",
    "\n",
    "for fname in files:\n",
    "    reagan_text += state_union.raw(fname).replace('\\n',' ').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:13:32.072567Z",
     "start_time": "2019-03-01T21:13:32.030913Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bill Clinton\n",
    "\n",
    "# 1.  Get all Reagan transcripts\n",
    "files = ['1993-Clinton.txt', '1994-Clinton.txt', \n",
    "         '1995-Clinton.txt', '1996-Clinton.txt', \n",
    "         '1997-Clinton.txt', '1998-Clinton.txt', \n",
    "         '1999-Clinton.txt', '2000-Clinton.txt',]\n",
    "clinton_text = \"\"\n",
    "\n",
    "for fname in files:\n",
    "    clinton_text += state_union.raw(fname).replace('\\n',' ').lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NLP Raw Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:13:45.773410Z",
     "start_time": "2019-03-01T21:13:34.461607Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en')\n",
    "reagan_doc = nlp(reagan_text)\n",
    "clinton_doc = nlp(clinton_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Break into sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:13:46.157800Z",
     "start_time": "2019-03-01T21:13:46.107613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>president</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(president, ronald, reagan, 's, address, befor...</td>\n",
       "      <td>Reagan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(speaker, ,, mr, .)</td>\n",
       "      <td>Reagan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(president, ,, distinguished, members, of, con...</td>\n",
       "      <td>Reagan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(i, 'm, here, tonight, to, reaffirm, that, ple...</td>\n",
       "      <td>Reagan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(all, of, us, are, aware, of, the, punishing, ...</td>\n",
       "      <td>Reagan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text president\n",
       "0  (president, ronald, reagan, 's, address, befor...    Reagan\n",
       "1                                (speaker, ,, mr, .)    Reagan\n",
       "2  (president, ,, distinguished, members, of, con...    Reagan\n",
       "3  (i, 'm, here, tonight, to, reaffirm, that, ple...    Reagan\n",
       "4  (all, of, us, are, aware, of, the, punishing, ...    Reagan"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "reagan_sents = [[sent, \"Reagan\"] for sent in reagan_doc.sents]\n",
    "clinton_sents = [[sent, \"Clinton\"] for sent in clinton_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(reagan_sents + clinton_sents, columns=['text','president'])\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let us get words that are common to both Presidents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T02:59:11.755519Z",
     "start_time": "2019-03-01T02:59:11.709341Z"
    }
   },
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:14:12.806801Z",
     "start_time": "2019-03-01T21:14:12.076144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "people        484\n",
       "america       424\n",
       "new           348\n",
       "year          321\n",
       "years         320\n",
       "work          303\n",
       "american      271\n",
       "government    257\n",
       "congress      253\n",
       "world         244\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english') #, min_df=4, max_df=.7)\n",
    "bow = cv.fit_transform(sentences.text.astype(str), sentences.president).toarray()\n",
    "bow = pd.DataFrame(bow, columns=cv.get_feature_names())\n",
    "bow.sum(axis=0).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:14:15.486243Z",
     "start_time": "2019-03-01T21:14:15.480397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4481, 6633)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:14:35.034683Z",
     "start_time": "2019-03-01T21:14:34.280787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "people       75.434830\n",
       "america      74.819466\n",
       "work         63.258179\n",
       "let          60.248949\n",
       "year         57.842328\n",
       "new          55.523233\n",
       "years        55.172134\n",
       "americans    49.432571\n",
       "american     48.379614\n",
       "congress     48.119739\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tcv = TfidfVectorizer(stop_words='english') #, min_df=4, max_df=.1 )\n",
    "tfidf = tcv.fit_transform(sentences.text.astype(str), sentences.president).toarray()\n",
    "tfidf = pd.DataFrame(tfidf, columns=tcv.get_feature_names())\n",
    "\n",
    "tfidf.sum(axis=0).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:14:37.905946Z",
     "start_time": "2019-03-01T21:14:37.900566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4481, 6633)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split** data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:14:47.336479Z",
     "start_time": "2019-03-01T21:14:46.833206Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_bow_train, X_bow_test, y_train, y_test = train_test_split(bow, \n",
    "                                                    sentences.president,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=0)\n",
    "\n",
    "X_tfidf_train, X_tfidf_test, y_train, y_test = train_test_split(tfidf, \n",
    "                                                    sentences.president,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models  \n",
    "\n",
    "## Bag of Words\n",
    "  1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:14:51.449434Z",
     "start_time": "2019-03-01T21:14:50.682646Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mitchellmurphy/anaconda3/envs/python3.5/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4032, 6633) (4032,)\n",
      "Training set score: 0.9439484126984127\n",
      "\n",
      "Test set score: 0.7639198218262806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_bow_train, y_train)\n",
    "print(X_bow_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_bow_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_bow_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, logistic regression overfits the training data big time! SVM's should help with this.     \n",
    "  2. Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:19:09.148027Z",
     "start_time": "2019-03-01T21:14:59.217580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4032, 6633) (4032,)\n",
      "Training set score: 0.9109623015873016\n",
      "\n",
      "Test set score: 0.7661469933184856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='poly', degree=1, gamma=.22)\n",
    "train_svc = svc.fit(X_bow_train, y_train)\n",
    "print(X_bow_train.shape, y_train.shape)\n",
    "print('Training set score:', svc.score(X_bow_train, y_train))\n",
    "print('\\nTest set score:', svc.score(X_bow_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we overfit our training data less, but we do see a lot of improvement on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:19:27.697441Z",
     "start_time": "2019-03-01T21:19:27.494253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4032, 6633) (4032,)\n",
      "Training set score: 0.8772321428571429\n",
      "\n",
      "Test set score: 0.7594654788418709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mitchellmurphy/anaconda3/envs/python3.5/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr2 = LogisticRegression()\n",
    "train = lr2.fit(X_tfidf_train, y_train)\n",
    "print(X_tfidf_train.shape, y_train.shape)\n",
    "print('Training set score:', lr2.score(X_tfidf_train, y_train))\n",
    "print('\\nTest set score:', lr2.score(X_tfidf_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:29:10.767675Z",
     "start_time": "2019-03-01T21:24:49.564730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9263392857142857\n",
      "\n",
      "Test set score: 0.7616926503340757\n"
     ]
    }
   ],
   "source": [
    "svc2 = SVC(kernel='linear')\n",
    "train_svc2 = svc2.fit(X_tfidf_train, y_train)\n",
    "print('Training set score:', svc2.score(X_tfidf_train, y_train))\n",
    "print('\\nTest set score:', svc2.score(X_tfidf_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF appears to be less prone to overfitting, however this is not a great model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Tagging \n",
    "Now let's add a few features, such as POS tagging, sentence and word length, polarity and subjectivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:25:29.495662Z",
     "start_time": "2019-03-01T17:23:18.608680Z"
    }
   },
   "source": [
    "## POS tagging plus bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:31:46.556444Z",
     "start_time": "2019-03-01T21:31:46.551852Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:31:02.067106Z",
     "start_time": "2019-03-01T21:31:02.060494Z"
    }
   },
   "outputs": [],
   "source": [
    "# should be more effiecent if we just replace every\n",
    "\n",
    "def sent_to_token_tag(text):\n",
    "    if text is not str:\n",
    "        text = str(text)\n",
    "\n",
    "    text = re.sub('[^a-zA-Z0-9]+', ' ', text)\n",
    "    tokens = text.split(' ')\n",
    "    # filter out punctuation and empty strings\n",
    "    tokens_ = [token for token in tokens if token not in STOPWORDS and token != '']\n",
    "    tt = dict(pos_tag(tokens_))\n",
    "    return ' '.join([k+'_'+v for k, v in tt.items()]) + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:31:53.059955Z",
     "start_time": "2019-03-01T21:31:49.003433Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences_pos = [sent_to_token_tag(sent) for sent in sentences.text]\n",
    "\n",
    "# create a 'bag of words' but this time a word is a token PLUS POS tag\n",
    "cv_pos = CountVectorizer()\n",
    "bow_pos = cv_pos.fit_transform(sentences_pos).toarray()\n",
    "bow_pos = pd.DataFrame(bow_pos, columns=cv_pos.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:31:56.618428Z",
     "start_time": "2019-03-01T21:31:55.944812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "people_nns       446\n",
       "must_md          426\n",
       "us_prp           331\n",
       "year_nn          292\n",
       "new_jj           291\n",
       "years_nns        288\n",
       "american_jj      259\n",
       "government_nn    231\n",
       "world_nn         226\n",
       "work_nn          220\n",
       "children_nns     219\n",
       "one_cd           212\n",
       "americans_nns    202\n",
       "every_dt         199\n",
       "congress_nn      195\n",
       "time_nn          192\n",
       "america_nn       172\n",
       "last_jj          172\n",
       "let_vb           156\n",
       "make_vbp         154\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_pos.sum(axis=0).sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add these 3 sets of features to our bag of words (or TF-IDF matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:37:00.205620Z",
     "start_time": "2019-03-01T21:36:56.425527Z"
    }
   },
   "outputs": [],
   "source": [
    "X_bow = bow.join(bow_pos) #.join(sentences.sentiment_score)\n",
    "X_tfidf = tfidf.join(bow_pos) #.join(sentences.sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:35:12.390868Z",
     "start_time": "2019-03-01T21:35:12.385569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4481, 16069)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:37:06.373155Z",
     "start_time": "2019-03-01T21:37:03.735674Z"
    }
   },
   "outputs": [],
   "source": [
    "X_bow_pos_train, X_bow_pos_test, y_train, y_test = train_test_split(X_bow, \n",
    "                                                    sentences.president,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=0)\n",
    "\n",
    "X_tfidf_pos_train, X_tfidf_pos_test, y_train, y_test = train_test_split(X_tfidf, \n",
    "                                                    sentences.president,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:37:14.101790Z",
     "start_time": "2019-03-01T21:37:11.649940Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mitchellmurphy/anaconda3/envs/python3.5/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4032, 16068) (4032,)\n",
      "Training set score: 0.9749503968253969\n",
      "\n",
      "Test set score: 0.7683741648106904\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_bow_pos_train, y_train)\n",
    "print(X_bow_pos_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_bow_pos_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_bow_pos_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-01T21:38:42.936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4032, 16068) (4032,)\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='poly', degree=1, gamma=.22)\n",
    "train_svc = svc.fit(X_bow_pos_train, y_train)\n",
    "print(X_bow_pos_train.shape, y_train.shape)\n",
    "print('Training set score:', svc.score(X_bow_pos_train, y_train))\n",
    "print('\\nTest set score:', svc.score(X_bow_pos_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
