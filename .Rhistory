paste(my_char, collapse = " ")
my_name <- c(my_char, "Mitchell Murphy")
my_name
paste(my_name, collapse = " ")
paste("Hello", "world!", sep = " ")
paste(c(1:3,c("X","Y","Z")), sep = "")
paste(1:3, c("X", "Y", "Z"), sep = "")
paste(LETTERS, 1:4, sep = "-")
c(44, NA, 5, NA)
x <- c(44, NA, 5, NA)
x*3
y <- rnorm(1000)
z <- rep(NA, 1000)
my_data <- sample(c(y, z), 100)
my_na <- is.na(my_data)
my_na
my_data == NA
sum(my_na)
my_data
0/0
Inf-Inf
x
x[1:10]
x[is.na(x)]
y <- x[!is.na(x)]
y
y[y >0]
x[x>0]
x[!is.na(x) & x > 0]
x[c(3,5,7)]
x[0]
x[3000]
x[c(-2, -10)]
x[-c(2, 10)]
vect <- c(foo = 11, bar = 2, norf = NA)
vect
names(vect) <- c("foo", "bar", "norf")
names(vect)
vect2 <- c(11, 2, NA)
names(vect2) <- c("foo", "bar", "norf")
identical(vect, vect2)
vect["bar"]
vect[c("foo", "bar")]
my_vector <- 1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector) <- c(4, 5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix <- my_vector
?matrix
my_matrix2 <- matrix(1:20, nrow = 4, byrow = F)
identical(my_matrix, my_matrix2)
patients <- c("Bill", "Gina", "Kelly", "Sean")
cbind(my_vector, patients)
cbind(patients, my_matrix)
my_data <- data.frame(patients, my_matrix)
my_data
class(my_data)
cnames <- colnames(my_data)
cnames <- c("patient", "age", "weight", "bp", "rating", "test")
colnames(my_data) <- cnames
my_data
TRUE == TRUE
(FALSE == TRUE) == FALSE
6 == 7
6 < 7
10 <= 10
5 != 7
!(5 == 7)
FALSE & FALSE
TRUE & c(TRUE, FALSE, FALSE)
TRUE && c(TRUE, FALSE, FALSE)
TRUE | c(TRUE, FALSE, FALSE)
TRUE || c(TRUE, FALSE, FALSE)
5 > 8 || 6 != 8 && 4 > 3.9
isTRUE(6 > 4)
identical('twins', 'twins')
xor(5 == 6, !FALSE)
ints <- sample(10)
ints
ints > 5
which(ints>7)
any(ints<0)
all(ints>0)
Sys.Date()
mean(c(2, 4, 5))
submit()
boring_function('My first function')
boring_function('My first function!')
boring_function
submit()
my_mean(c(4, 5, 10))
bye()
x <- sample(c(0,1),1000)
?sample
x <- sample(c(0,1),1,100)
x
x <- sample(c(0,1),n=1,size=100)
getwd()
directory <- "/Users/mitchellmurphy/DataScience/datasets/specdata/"
setwd(directory)
setwd(""/Users/mitchellmurphy/DataScience/datasets/specdata/"")
setwd("/Users/mitchellmurphy/DataScience/datasets/specdata/")
setwd("/Users/mitchellmurphy/DataScience/datasets/specdata/")
setwd("/Users/mitchellmurphy/Desktop/DataScience/datasets/specdat/")
dir()
rnorm(2*2*10)
c(2,2,10)
rm(rate, envir = .GlobalEnv)
?mapply
mapply(rep, 1:4, 4:1)
?noise
?gl
gl(4,10)
?tapply(vector, index, function)
?tapply
x <- gl(3,20)
head(x)
typeof(x)
levels(x)
split(x,levelsx)
split(x,levels(x))
library(datasets)
levels(airquality)
colnames(airquality)
head(airquality)
levels(airquality$Month)
?split
monthly <- split(airquality, airquality$Month)
monthly
typeof(airquality$Month)
lapply(monthly, mean)
View(monthly)
avg.temps <- lapply(monthly, function(x) { colMeans(x[,"Temp"]) })
avg.temps <- lapply(monthly, function(x) colMeans(x[,"Temp"]) )
lapply(monthly, function(x) colMeans(x[,"Temp"]))
lapply(monthly, function(x) colMeans(x[,c("Ozone", Temp")]))
lapply(monthly, function(x) colMeans(x[,c("Ozone", Temp"))]))
rm(x)
lapply(monthly, function(x) { return(colMeans(x[,"Temp"])) })
s <- monthly
s
lapply(s, function(x) colMeans(x[,c("Ozone", "Solar.R", "Wind")]))
lapply(s, function(x) colMeans(x[,c("Temp")]))
factor(airquality$Month)
lapply(s, function(x) colMeans(x[,c("Ozone", "Solar.R", "Wind")]))
lapply(s, function(x) colMeans(x[,c("Ozone", "Temp", "Wind")]))
head(monthly)
View(monthly)
lapply(s, function(x) colMeans(x[,c("Ozone", "Temp", "Wind")], na.rm = T))
rm(s)
sapply(monthly, function(x) colMeans(x[,"Temp"]))
sapply(monthly, function(x) colMeans(x[,"Ozone",Temp"]))
sapply(monthly, function(x) colMeans(x[,c("Ozone", "Temp")]))
sapply(monthly, function(x) colMeans(x[,c("Ozone", "Temp")]), na.rm = T)
sapply(monthly, function(x) colMeans(x[,c("Ozone", "Temp")], na.rm = T))
sapply(monthly, function(x) colMeans(x))
sapply(monthly, function(x) colMeans(x, na.rm = T))
?interaction
f1 <- gl(2,5)
f2 <- gl(5,2)
interaction(f1,f2)
log(-1)
log(Inf)
log(0)
traceback()
x <- rnorm(100])
x <- rnorm(100)
y <- rnorm(100)
mf <- model.frame(y~x)
mf
mdl <- lm(y~x)
summary(mdl)
?predict
?eval
x2 <- rnorm(10)
predict(mdl, newdata = x2)
predict(mdl,x2)
data("iris")
data(iris)
head(iris)
View(iris)
?split
mean(iris[iris$Species == "virginica"])
mean(iris[iris$Species == "virginica",'Sepal.Length'])
split(iris, iris$Species)
sapply(split(iris, iris$Species), mean)
iris.species <- split(iris, iris$Species)
View(iris.species)
mean(iris.species$virginica)
mean(iris.species$virginica[,"Sepal.Width"])
mean(iris.species$virginica[,"Sepal.Length"])
apply(iris[, 1:4], 1, mean)
head(iris[,1:4])
?apply
library(datasets)
data("mtcars")
head(mtcars)
tapply(mtcars$mpg, mtcars$cyl, mean)
?tapply(vector, index, function)
?tapply
apply(mtcars, 2, mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
lapply(mtcars, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
mean(mtcars$mpg, mtcars$cyl)
sapply(mtcars, cyl, mean)
tapply(mtcars$hp, mtcars$cyl, mean)
122.28571-82.63636
debug(ls)
ls()
?with
with(mtcars, tapply(hp, cyl, mean))
209.21429-82.63636
rm(rate)
library(datasets)
data(iris)
head(iris)
?sapply
sapply(split(iris$Sepal.Length, iris$Species), mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
sapply(split(mtcars$hp, mtcars$cyl), mean)
209.21429-82.63636
?grep
?solve
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
cachemean <- function(x, ...) {
m <- x$getmean()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
makeCacheMatrix <- function(m = matrix()) {
inv <- NULL #placeholder for inverse
get <- function() m
set <- function(mat) {
m <<- mat
i <<- NULL
}
# also need getter and setter for inv
getInverse <- function() inv
setInverse <- function(i) {
inv <<- i
}
# return list of all 4 of these properties
list(get = get, set = set, getInverse = getInverse, setInverse = setInverse)
}
cacheSolve <- function(x, ...) {
inv <- x$getInverse()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
inv <- solve(data)
x$setInverse(inv)
inv
}
x <- seq(0,1,100)
head(x)
?seq
x <- seq(from =0, to = 1, by = 0.01)
head(x)
?log
y <- log10(x)
head(y)
tail(y)
y <- log(x)
head(y)
tail(y)
head(log2(x))
head(log(x))
log1p(0)
log(1)
log1p(1)
log(2)
?lag
install.packages("RMySQL")
library(RMySQL)
ucscDb <- dbConnect(MySQL(),user = "genome", host = "genome-mysql.soe.ucsc.edu")
result <- dbGetQuery(ucscDb, "show databases;"); dbDisconnect(ucscDb);
result
typeof(result)
typeof(ucscDb)
dbUser <- "genome"
dbHost <- "genome-mysql.soe.ucsc.edu"
hg19 <- dbConnect(MySQL(), user =dbUser, db = "hg19", host = dbHost)
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
typeof(allTables)
dbListFields(hg19, "HInv")
dbListFields(hg19, allTables[1])
allTables[1:100]
dbListFields(hg19, "affyU133Plus2")
dbGetQuery(hg19, "select count(*) affyU133Plus2")
dbGetQuery(hg19, "select count(*) affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
affyData <- dbReadTable(hg19, "affyU133Plus2")
head(affyData)
data <- dbGetQuery(hg19, "select * from affyU133Plus2")
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatch between 1 and 3")
head(data)
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
type.convert(query)
typeof(query)
affyMis <- fetch(query); quantile(affyMis$misMatches)
head(affyMis)
dim(affyMis)
affyMisSmall <- fetch(query, n=10); dbClearResult(query);
dim(affyMisSmall)
query
dbDisconnect(hg19)
source("https://bioconductor.org/biocLite.R")
source("https://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
created = h5createFile("example.h5")
created
typeof(created)
dir()
if(created) {
createdGroup1 <- h5createGroup("example.h5", "foo")
createdGroup2 <- h5createGroup("example.h5", "bar")
if(createdGroup1) {
createdGroup3 <- h5createGroup("example.h5", "foo/foobar")
}
}
h5ls("example.h5")
install.packages(c("jpeg", "png", "bmp"))
library(jpeg)
img <- readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
img <- readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", "jeff.jpg")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", "jeff.jpg", mode = "wb")
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
, 'jeff.jpg'
, mode='wb' )
img <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
img <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", "jeff.jpg")
library(data.table)
dt <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
dt <- data.table(dt)
head(dt)
dt <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
head(dt)
dt <- data.table(dt)
GDP <- dt
rm(dt)
ed <- data.table::fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv")
EDU <- data.table::fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv")
GDP <- fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
rm(ed)
rm(img)
rm(rate)
cameraData <- fread("https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD")
View(cameraData)
tolower(names(cameraData))
names(cameraData)
names(cameraData) <- tolower(names(cameraData))
names(cameraData)
splitNames <- strsplit(names(cameraData), "\\.")
splitNames
splitNames[[6]]
splitNames[[6]][[1]]
firstElement <- function(x) { x[1] }
sapply(splitNames, firstElement)
reviews <- read.csv("https://github.com/jtleek/dataanalysis/blob/master/week2/007summarizingData/data/reviews.csv")
solutions <- read.csv("https://github.com/jtleek/dataanalysis/blob/master/week2/007summarizingData/data/solutions.csv")
?sub
sub("_", "", names(reviews),)
View(reviews)
reviews <- read.csv("https://raw.githubusercontent.com/jtleek/dataanalysis/master/week2/007summarizingData/data/reviews.csv")
reviews <- read.csv("https://raw.githubusercontent.com/jtleek/dataanalysis/master/week2/007summarizingData/data/reviews.csv")
solutions <- read.csv("https://raw.githubusercontent.com/jtleek/dataanalysis/master/week2/007summarizingData/data/solutions.csv")
names(reviews)
sub("_","", names(reviews))
names(reviews)
names(reviews) <- sub("_","", names(reviews))
names(reviews)
length("This is a test")
paste("Mitch", "Murphy")
paste("Mitch", "Murphy", sep = " ")
paste0("Mitch", "Murphy")
paste("Mitch", "Murphy", sep = "")
?date
Sys.Date()
Sys.setenv(TZ = "America/New_York")
Sys.getenv("TZ")
as.POSIXct(t, tz=getOption("tz"))
Sys.Date()
Sys.Date()
?format
dte <- format(Sys.Date(), "%m/%d/%Y")
dte
date2 <- as.Date("02/11/2018")
date2
date2 - dte
class(dte)
class(date2)
date2 <- format("02/11/2018", "%m/%d/%Y")
format(Sys.Date(), "%m/%d/%Y")
format(Sys.Date(), "%m/%d/%Y") + 14
julian(dte)
julian(Sys.time())
library(data.table)
ACS <- fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
View(ACS)
names(ACS)
?`datasets-package`
install.packages("data.table")
require(data.table)
init <- function(base_directory = "~/Desktop/DataScience/coursera/") {
# Set the working directory
setwd(base_directory)
# Load needed packages
library(data.table)
library(reshape2)
}
downloadData <- function() {
# Ensure that the UCI data exists in the current working directory.
# If it does not, download the zip file and then unzip it
#
# Args: nothing
# Returns: nothing
dataDirectory <<- paste(getwd(), "data/UCI HAR Dataset", sep = "/")
if(!dir.exists(dataDirectory)) {
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile = "data/UCI HAR Dataset.zip")
unzip(paste0(dataDirectory, ".zip"))
}
# first check if the data is already there. If not, download it
}
## This function will read in both the train and test sets
## and cleans it up so we just have a train and test data.tables
## Not split into 2 functions due to how I use lexical scoping
readAndCleanData <- function() {
# Read in the raw, unformatted data
# "Clean it up" by only extracting the necessary columns (features)
#  Repeat this process for both the train and test data sets
#
# Args: none
#
# Returns: officially nothing is returned from this function,
#   however the formatted train and test data sets are added to the global environment
dataDirectory <- paste(getwd(),"data/UCI HAR Dataset/",sep = "/")
# Read data
activityLabels <<- fread(paste0(dataDirectory, "activity_labels.txt"), col.names = c("classLabels", "activityName"))
features <- fread(paste0(dataDirectory, "features.txt"), col.names = c("index", "featureNames"))
featuresToInclude <- grep(".*mean.*|.*std.*", features[, featureNames])
measurements <- features[featuresToInclude,featureNames]
measurements <- gsub('[()]', '', measurements)
train.x <- fread(paste0(dataDirectory,"train/X_train.txt"))[, featuresToInclude, with = FALSE]
data.table::setnames(train.x, colnames(train.x), measurements)
train.y <- fread(paste0(dataDirectory,"train/Y_train.txt"), col.names = c("Activity"))
train.subjects <- fread(paste0(dataDirectory,"train/subject_train.txt"), col.names = c("SubjectNum"))
train <<- cbind(train.subjects, train.y, train.x)
# Now load up the test data
test.x <- fread(paste0(dataDirectory,"test/X_test.txt"))[, featuresToInclude, with = FALSE]
data.table::setnames(test.x, colnames(test.x), measurements)
test.y <- fread(paste0(dataDirectory,"test/Y_test.txt"), col.names = c("Activity"))
test.subjects <- fread(paste0(dataDirectory,"test/subject_test.txt"), col.names = c("SubjectNum"))
test <<- cbind(test.subjects, test.y, test.x)
}
init()
# this function will do most of the work for us (reading and cleaning up the data)
downloadData()
readAndCleanData()
## Merges the training and the test sets to create one data set.
if(is.null(train) & is.null(test)) {
stop("train and test variables do not exist. Make sure you first call readAndClean()")
}
total <- rbind(train, test)
rm(train, test)
## Coerce the SubjectNum column into factors
total$SubjectNum <- as.factor(total$SubjectNum)
#total$SubjectNum <- NULL
# Now let us map the Activity number into its equiv name (read from activities.txt) in activitesLabel list
total$Activity <- factor(total$Activity, levels = activityLabels[["classLabels"]], labels = activityLabels[["activityName"]])
## From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject
## This will be our final, "tidy" data set
total <- reshape2::melt(data = total, id = c("SubjectNum", "Activity"))
total <- reshape2::dcast(data = total, SubjectNum + Activity ~ variable, fun.aggregate = mean)
?require
## Now save (write) this data table to disk
data.table::fwritewrite(total, file = paste(dataDirectory, "tidyData.txt", sep = "/"))
data.table::fwrite(x = total, file = "tidyData.txt", quote = FALSE)
data.table::fwrite(x = total, file = paste(dataDirectory, "tidyData.txt", sep = "/"), quote = FALSE)
dir()
mydata <- fread("data/UCI HAR Dataset/tidyData.txt")
