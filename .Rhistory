if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
makeCacheMatrix <- function(m = matrix()) {
inv <- NULL #placeholder for inverse
get <- function() m
set <- function(mat) {
m <<- mat
i <<- NULL
}
# also need getter and setter for inv
getInverse <- function() inv
setInverse <- function(i) {
inv <<- i
}
# return list of all 4 of these properties
list(get = get, set = set, getInverse = getInverse, setInverse = setInverse)
}
cacheSolve <- function(x, ...) {
inv <- x$getInverse()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
inv <- solve(data)
x$setInverse(inv)
inv
}
x <- seq(0,1,100)
head(x)
?seq
x <- seq(from =0, to = 1, by = 0.01)
head(x)
?log
y <- log10(x)
head(y)
tail(y)
y <- log(x)
head(y)
tail(y)
head(log2(x))
head(log(x))
log1p(0)
log(1)
log1p(1)
log(2)
?lag
install.packages("RMySQL")
library(RMySQL)
ucscDb <- dbConnect(MySQL(),user = "genome", host = "genome-mysql.soe.ucsc.edu")
result <- dbGetQuery(ucscDb, "show databases;"); dbDisconnect(ucscDb);
result
typeof(result)
typeof(ucscDb)
dbUser <- "genome"
dbHost <- "genome-mysql.soe.ucsc.edu"
hg19 <- dbConnect(MySQL(), user =dbUser, db = "hg19", host = dbHost)
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
typeof(allTables)
dbListFields(hg19, "HInv")
dbListFields(hg19, allTables[1])
allTables[1:100]
dbListFields(hg19, "affyU133Plus2")
dbGetQuery(hg19, "select count(*) affyU133Plus2")
dbGetQuery(hg19, "select count(*) affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
affyData <- dbReadTable(hg19, "affyU133Plus2")
head(affyData)
data <- dbGetQuery(hg19, "select * from affyU133Plus2")
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatch between 1 and 3")
head(data)
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
type.convert(query)
typeof(query)
affyMis <- fetch(query); quantile(affyMis$misMatches)
head(affyMis)
dim(affyMis)
affyMisSmall <- fetch(query, n=10); dbClearResult(query);
dim(affyMisSmall)
query
dbDisconnect(hg19)
source("https://bioconductor.org/biocLite.R")
source("https://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
created = h5createFile("example.h5")
created
typeof(created)
dir()
if(created) {
createdGroup1 <- h5createGroup("example.h5", "foo")
createdGroup2 <- h5createGroup("example.h5", "bar")
if(createdGroup1) {
createdGroup3 <- h5createGroup("example.h5", "foo/foobar")
}
}
h5ls("example.h5")
install.packages(c("jpeg", "png", "bmp"))
library(jpeg)
img <- readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
img <- readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", "jeff.jpg")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", "jeff.jpg", mode = "wb")
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
, 'jeff.jpg'
, mode='wb' )
img <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
img <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", "jeff.jpg")
library(data.table)
dt <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
dt <- data.table(dt)
head(dt)
dt <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
head(dt)
dt <- data.table(dt)
GDP <- dt
rm(dt)
ed <- data.table::fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv")
EDU <- data.table::fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv")
GDP <- fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
rm(ed)
rm(img)
rm(rate)
cameraData <- fread("https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD")
View(cameraData)
tolower(names(cameraData))
names(cameraData)
names(cameraData) <- tolower(names(cameraData))
names(cameraData)
splitNames <- strsplit(names(cameraData), "\\.")
splitNames
splitNames[[6]]
splitNames[[6]][[1]]
firstElement <- function(x) { x[1] }
sapply(splitNames, firstElement)
reviews <- read.csv("https://github.com/jtleek/dataanalysis/blob/master/week2/007summarizingData/data/reviews.csv")
solutions <- read.csv("https://github.com/jtleek/dataanalysis/blob/master/week2/007summarizingData/data/solutions.csv")
?sub
sub("_", "", names(reviews),)
View(reviews)
reviews <- read.csv("https://raw.githubusercontent.com/jtleek/dataanalysis/master/week2/007summarizingData/data/reviews.csv")
reviews <- read.csv("https://raw.githubusercontent.com/jtleek/dataanalysis/master/week2/007summarizingData/data/reviews.csv")
solutions <- read.csv("https://raw.githubusercontent.com/jtleek/dataanalysis/master/week2/007summarizingData/data/solutions.csv")
names(reviews)
sub("_","", names(reviews))
names(reviews)
names(reviews) <- sub("_","", names(reviews))
names(reviews)
length("This is a test")
paste("Mitch", "Murphy")
paste("Mitch", "Murphy", sep = " ")
paste0("Mitch", "Murphy")
paste("Mitch", "Murphy", sep = "")
?date
Sys.Date()
Sys.setenv(TZ = "America/New_York")
Sys.getenv("TZ")
as.POSIXct(t, tz=getOption("tz"))
Sys.Date()
Sys.Date()
?format
dte <- format(Sys.Date(), "%m/%d/%Y")
dte
date2 <- as.Date("02/11/2018")
date2
date2 - dte
class(dte)
class(date2)
date2 <- format("02/11/2018", "%m/%d/%Y")
format(Sys.Date(), "%m/%d/%Y")
format(Sys.Date(), "%m/%d/%Y") + 14
julian(dte)
julian(Sys.time())
library(data.table)
ACS <- fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
View(ACS)
names(ACS)
library(data.table)
data <- fread("https://s3.amazonaws.com/coursera-uploads/peer-review/67d0fcba26ddcabe5ebfa4619e5fe2be/tidyDS.txt")
myData <- fread("/Users/mitchellmurphy/Desktop/DataScience/coursera/data/UCI\ HAR\ Dataset/tidyData.txt")
colnames(data)
rm(myData)
tidyData1 <- fread("https://raw.githubusercontent.com/mGalarnyk/datasciencecoursera/master/3_Getting_and_Cleaning_Data/data/tidyData.txt")
tidyData2 <- fread("https://raw.githubusercontent.com/bgentry/coursera-getting-and-cleaning-data-project/master/tidy.txt")
colnames(tidyData1)
colnames(tidyData2)
setdiff(colnames(tidyData1, tidyData2))
A <- colnames(tidyData1)
B <- colnames(tidyData2)
typeof(A)
typeof(B)
union(A,B)
setdiff(A,B)
init <- function(base_directory = "~/Desktop/DataScience/coursera/") {
# Set the working directory
setwd(base_directory)
# Load needed packages
library(data.table)
library(reshape2)
}
downloadData <- function() {
# Ensure that the UCI data exists in the current working directory.
# If it does not, download the zip file and then unzip it
#
# Args: nothing
# Returns: nothing
dataDirectory <<- paste(getwd(), "data/UCI HAR Dataset", sep = "/")
if(!dir.exists(dataDirectory)) {
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile = "data/UCI HAR Dataset.zip")
unzip(paste0(dataDirectory, ".zip"))
}
# first check if the data is already there. If not, download it
}
## This function will read in both the train and test sets
## and cleans it up so we just have a train and test data.tables
## Not split into 2 functions due to how I use lexical scoping
readAndCleanData <- function() {
# Read in the raw, unformatted data
# "Clean it up" by only extracting the necessary columns (features)
#  Repeat this process for both the train and test data sets
#
# Args: none
#
# Returns: officially nothing is returned from this function,
#   however the formatted train and test data sets are added to the global environment
dataDirectory <- paste(getwd(),"data/UCI HAR Dataset/",sep = "/")
# Read data
activityLabels <<- fread(paste0(dataDirectory, "activity_labels.txt"), col.names = c("classLabels", "activityName"))
features <- fread(paste0(dataDirectory, "features.txt"), col.names = c("index", "featureNames"))
featuresToInclude <- grep("(mean|std)\\(\\)", features[, featureNames])
measurements <- features[featuresToInclude,featureNames]
measurements <- gsub('[()]', '', measurements)
train.x <- fread(paste0(dataDirectory,"train/X_train.txt"))[, featuresToInclude, with = FALSE]
data.table::setnames(train.x, colnames(train.x), measurements)
train.y <- fread(paste0(dataDirectory,"train/Y_train.txt"), col.names = c("Activity"))
train.subjects <- fread(paste0(dataDirectory,"train/subject_train.txt"), col.names = c("SubjectNum"))
train <<- cbind(train.subjects, train.y, train.x)
# Now load up the test data
test.x <- fread(paste0(dataDirectory,"test/X_test.txt"))[, featuresToInclude, with = FALSE]
data.table::setnames(test.x, colnames(test.x), measurements)
test.y <- fread(paste0(dataDirectory,"test/Y_test.txt"), col.names = c("Activity"))
test.subjects <- fread(paste0(dataDirectory,"test/subject_test.txt"), col.names = c("SubjectNum"))
test <<- cbind(test.subjects, test.y, test.x)
}
init()
# this function will do most of the work for us (reading and cleaning up the data)
downloadData()
readAndCleanData <- function() {
# Read in the raw, unformatted data
# "Clean it up" by only extracting the necessary columns (features)
#  Repeat this process for both the train and test data sets
#
# Args: none
#
# Returns: officially nothing is returned from this function,
#   however the formatted train and test data sets are added to the global environment
dataDirectory <- paste(getwd(),"data/UCI HAR Dataset/",sep = "/")
# Read data
activityLabels <<- fread(paste0(dataDirectory, "activity_labels.txt"), col.names = c("classLabels", "activityName"))
features <- fread(paste0(dataDirectory, "features.txt"), col.names = c("index", "featureNames"))
featuresToInclude <- grep(".*mean.*|.*std.*", features[, 2])
measurements <- features[featuresToInclude,2]
measurements <- gsub('[()]', '', measurements)
train.x <- fread(paste0(dataDirectory,"train/X_train.txt"))[, featuresToInclude, with = FALSE]
data.table::setnames(train.x, colnames(train.x), measurements)
train.y <- fread(paste0(dataDirectory,"train/Y_train.txt"), col.names = c("Activity"))
train.subjects <- fread(paste0(dataDirectory,"train/subject_train.txt"), col.names = c("SubjectNum"))
train <<- cbind(train.subjects, train.y, train.x)
# Now load up the test data
test.x <- fread(paste0(dataDirectory,"test/X_test.txt"))[, featuresToInclude, with = FALSE]
data.table::setnames(test.x, colnames(test.x), measurements)
test.y <- fread(paste0(dataDirectory,"test/Y_test.txt"), col.names = c("Activity"))
test.subjects <- fread(paste0(dataDirectory,"test/subject_test.txt"), col.names = c("SubjectNum"))
test <<- cbind(test.subjects, test.y, test.x)
}
readAndCleanData()
readAndCleanData <- function() {
# Read in the raw, unformatted data
# "Clean it up" by only extracting the necessary columns (features)
#  Repeat this process for both the train and test data sets
#
# Args: none
#
# Returns: officially nothing is returned from this function,
#   however the formatted train and test data sets are added to the global environment
dataDirectory <- paste(getwd(),"data/UCI HAR Dataset/",sep = "/")
# Read data
activityLabels <<- fread(paste0(dataDirectory, "activity_labels.txt"), col.names = c("classLabels", "activityName"))
features <- fread(paste0(dataDirectory, "features.txt"), col.names = c("index", "featureNames"))
featuresToInclude <- grep(".*mean.*|.*std.*", features[, featureNames])
measurements <- features[featuresToInclude,featureNames]
measurements <- gsub('[()]', '', measurements)
train.x <- fread(paste0(dataDirectory,"train/X_train.txt"))[, featuresToInclude, with = FALSE]
data.table::setnames(train.x, colnames(train.x), measurements)
train.y <- fread(paste0(dataDirectory,"train/Y_train.txt"), col.names = c("Activity"))
train.subjects <- fread(paste0(dataDirectory,"train/subject_train.txt"), col.names = c("SubjectNum"))
train <<- cbind(train.subjects, train.y, train.x)
# Now load up the test data
test.x <- fread(paste0(dataDirectory,"test/X_test.txt"))[, featuresToInclude, with = FALSE]
data.table::setnames(test.x, colnames(test.x), measurements)
test.y <- fread(paste0(dataDirectory,"test/Y_test.txt"), col.names = c("Activity"))
test.subjects <- fread(paste0(dataDirectory,"test/subject_test.txt"), col.names = c("SubjectNum"))
test <<- cbind(test.subjects, test.y, test.x)
}
readAndCleanData()
?rm
rm(test, train)
## Merges the training and the test sets to create one data set.
if(is.null(train) & is.null(test)) {
stop("train and test variables do not exist. Make sure you first call readAndClean()")
}
total <- rbind(train, test)
rm(train, test)
## Coerce the SubjectNum column into factors
total$SubjectNum <- as.factor(total$SubjectNum)
# Now let us map the Activity number into its equiv name (read from activities.txt) in activitesLabel list
total$Activity <- factor(total$Activity, levels = activityLabels[["classLabels"]], labels = activityLabels[["activityName"]])
## From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject
## This will be our final, "tidy" data set
total <- reshape2::melt(data = total, id = c("SubjectNum", "Activity"))
total <- reshape2::dcast(data = total, SubjectNum + Activity ~ variable, fun.aggregate = mean)
## Now save (write) this data table to disk
write.table(total, file = paste(dataDirectory, "tidyData.txt", sep = "/"))
init <- function(base_directory = "~/Desktop/DataScience/coursera/") {
# Set the working directory
setwd(base_directory)
# Load needed packages
library(data.table)
library(reshape2)
}
downloadData <- function() {
# Ensure that the UCI data exists in the current working directory.
# If it does not, download the zip file and then unzip it
#
# Args: nothing
# Returns: nothing
dataDirectory <<- paste(getwd(), "data/UCI HAR Dataset", sep = "/")
if(!dir.exists(dataDirectory)) {
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile = "data/UCI HAR Dataset.zip")
unzip(paste0(dataDirectory, ".zip"))
}
# first check if the data is already there. If not, download it
}
## This function will read in both the train and test sets
## and cleans it up so we just have a train and test data.tables
## Not split into 2 functions due to how I use lexical scoping
readAndCleanData <- function() {
# Read in the raw, unformatted data
# "Clean it up" by only extracting the necessary columns (features)
#  Repeat this process for both the train and test data sets
#
# Args: none
#
# Returns: officially nothing is returned from this function,
#   however the formatted train and test data sets are added to the global environment
dataDirectory <- paste(getwd(),"data/UCI HAR Dataset/",sep = "/")
# Read data
activityLabels <<- fread(paste0(dataDirectory, "activity_labels.txt"), col.names = c("classLabels", "activityName"))
features <- fread(paste0(dataDirectory, "features.txt"), col.names = c("index", "featureNames"))
featuresToInclude <- grep(".*mean.*|.*std.*", features[, featureNames])
measurements <- features[featuresToInclude,featureNames]
measurements <- gsub('[()]', '', measurements)
train.x <- fread(paste0(dataDirectory,"train/X_train.txt"))[, featuresToInclude, with = FALSE]
data.table::setnames(train.x, colnames(train.x), measurements)
train.y <- fread(paste0(dataDirectory,"train/Y_train.txt"), col.names = c("Activity"))
train.subjects <- fread(paste0(dataDirectory,"train/subject_train.txt"), col.names = c("SubjectNum"))
train <<- cbind(train.subjects, train.y, train.x)
# Now load up the test data
test.x <- fread(paste0(dataDirectory,"test/X_test.txt"))[, featuresToInclude, with = FALSE]
data.table::setnames(test.x, colnames(test.x), measurements)
test.y <- fread(paste0(dataDirectory,"test/Y_test.txt"), col.names = c("Activity"))
test.subjects <- fread(paste0(dataDirectory,"test/subject_test.txt"), col.names = c("SubjectNum"))
test <<- cbind(test.subjects, test.y, test.x)
}
init()
# this function will do most of the work for us (reading and cleaning up the data)
downloadData()
readAndCleanData()
if(is.null(train) & is.null(test)) {
stop("train and test variables do not exist. Make sure you first call readAndClean()")
}
total <- rbind(train, test)
rm(train, test)
## Coerce the SubjectNum column into factors
total$SubjectNum <- as.factor(total$SubjectNum)
total$Activity <- factor(total$Activity, levels = activityLabels[["classLabels"]], labels = activityLabels[["activityName"]])
## From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject
## This will be our final, "tidy" data set
total <- reshape2::melt(data = total, id = c("SubjectNum", "Activity"))
total <- reshape2::dcast(data = total, SubjectNum + Activity ~ variable, fun.aggregate = mean)
## Now save (write) this data table to disk
write.table(total, file = paste(dataDirectory, "tidyData.txt", sep = "/"))
mydata <- fread("https://s3.amazonaws.com/coursera-uploads/peer-review/e3f48c2e3edbee03243d160291d0cd9d/tidyData.txt")
tinyData1 <- fread("https://s3.amazonaws.com/coursera-uploads/peer-review/67d0fcba26ddcabe5ebfa4619e5fe2be/tidyDS.txt")
colnames(mydata)
init <- function(base_directory = "~/Desktop/DataScience/coursera/") {
# Set the working directory
setwd(base_directory)
# Load needed packages
library(data.table)
library(reshape2)
}
downloadData <- function() {
# Ensure that the UCI data exists in the current working directory.
# If it does not, download the zip file and then unzip it
#
# Args: nothing
# Returns: nothing
dataDirectory <<- paste(getwd(), "data/UCI HAR Dataset", sep = "/")
if(!dir.exists(dataDirectory)) {
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile = "data/UCI HAR Dataset.zip")
unzip(paste0(dataDirectory, ".zip"))
}
# first check if the data is already there. If not, download it
}
## This function will read in both the train and test sets
## and cleans it up so we just have a train and test data.tables
## Not split into 2 functions due to how I use lexical scoping
readAndCleanData <- function() {
# Read in the raw, unformatted data
# "Clean it up" by only extracting the necessary columns (features)
#  Repeat this process for both the train and test data sets
#
# Args: none
#
# Returns: officially nothing is returned from this function,
#   however the formatted train and test data sets are added to the global environment
dataDirectory <- paste(getwd(),"data/UCI HAR Dataset/",sep = "/")
# Read data
activityLabels <<- fread(paste0(dataDirectory, "activity_labels.txt"), col.names = c("classLabels", "activityName"))
features <- fread(paste0(dataDirectory, "features.txt"), col.names = c("index", "featureNames"))
featuresToInclude <- grep(".*mean.*|.*std.*", features[, featureNames])
measurements <- features[featuresToInclude,featureNames]
measurements <- gsub('[()]', '', measurements)
train.x <- fread(paste0(dataDirectory,"train/X_train.txt"))[, featuresToInclude, with = FALSE]
data.table::setnames(train.x, colnames(train.x), measurements)
train.y <- fread(paste0(dataDirectory,"train/Y_train.txt"), col.names = c("Activity"))
train.subjects <- fread(paste0(dataDirectory,"train/subject_train.txt"), col.names = c("SubjectNum"))
train <<- cbind(train.subjects, train.y, train.x)
# Now load up the test data
test.x <- fread(paste0(dataDirectory,"test/X_test.txt"))[, featuresToInclude, with = FALSE]
data.table::setnames(test.x, colnames(test.x), measurements)
test.y <- fread(paste0(dataDirectory,"test/Y_test.txt"), col.names = c("Activity"))
test.subjects <- fread(paste0(dataDirectory,"test/subject_test.txt"), col.names = c("SubjectNum"))
test <<- cbind(test.subjects, test.y, test.x)
}
init()
# this function will do most of the work for us (reading and cleaning up the data)
downloadData()
readAndCleanData()
## Merges the training and the test sets to create one data set.
if(is.null(train) & is.null(test)) {
stop("train and test variables do not exist. Make sure you first call readAndClean()")
}
total <- rbind(train, test)
rm(train, test)
## Coerce the SubjectNum column into factors
total$SubjectNum <- as.factor(total$SubjectNum)
# Now let us map the Activity number into its equiv name (read from activities.txt) in activitesLabel list
total$Activity <- factor(total$Activity, levels = activityLabels[["classLabels"]], labels = activityLabels[["activityName"]])
## From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject
## This will be our final, "tidy" data set
total <- reshape2::melt(data = total, id = c("SubjectNum", "Activity"))
total <- reshape2::dcast(data = total, SubjectNum + Activity ~ variable, fun.aggregate = mean)
colnames(total)
## Now save (write) this data table to disk
write(total, file = paste(dataDirectory, "tidyData.txt", sep = "/"))
class(total)
write.csv(total, file = paste(dataDirectory, "tidyData.txt", sep = "/")
)
td <- read.csv(paste(dataDirectory, "tidyData.txt", sep = "/"))
colnames(total)
## Now save (write) this data table to disk
write(total[,-1], file = paste(dataDirectory, "tidyData.txt", sep = "/"))
head(total[,1])
head(total$SubjectNum)
## Coerce the SubjectNum column into factors
#total$SubjectNum <- as.factor(total$SubjectNum)
total$SubjectNum <- NULL
## Now save (write) this data table to disk
write(total, file = paste(dataDirectory, "tidyData.txt", sep = "/"))
colnames(total)
init()
# this function will do most of the work for us (reading and cleaning up the data)
downloadData()
readAndCleanData()
## Merges the training and the test sets to create one data set.
if(is.null(train) & is.null(test)) {
stop("train and test variables do not exist. Make sure you first call readAndClean()")
}
total <- rbind(train, test)
rm(train, test)
## Coerce the SubjectNum column into factors
total$SubjectNum <- as.factor(total$SubjectNum)
total$Activity <- factor(total$Activity, levels = activityLabels[["classLabels"]], labels = activityLabels[["activityName"]])
## From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject
## This will be our final, "tidy" data set
total <- reshape2::melt(data = total, id = c("SubjectNum", "Activity"))
total <- reshape2::dcast(data = total, SubjectNum + Activity ~ variable, fun.aggregate = mean)
View(total)
## Now save (write) this data table to disk
write(total, file = paste(dataDirectory, "tidyData.txt", sep = "/"))
search()
