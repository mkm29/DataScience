class(my_data)
cnames <- colnames(my_data)
cnames <- c("patient", "age", "weight", "bp", "rating", "test")
colnames(my_data) <- cnames
my_data
TRUE == TRUE
(FALSE == TRUE) == FALSE
6 == 7
6 < 7
10 <= 10
5 != 7
!(5 == 7)
FALSE & FALSE
TRUE & c(TRUE, FALSE, FALSE)
TRUE && c(TRUE, FALSE, FALSE)
TRUE | c(TRUE, FALSE, FALSE)
TRUE || c(TRUE, FALSE, FALSE)
5 > 8 || 6 != 8 && 4 > 3.9
isTRUE(6 > 4)
identical('twins', 'twins')
xor(5 == 6, !FALSE)
ints <- sample(10)
ints
ints > 5
which(ints>7)
any(ints<0)
all(ints>0)
Sys.Date()
mean(c(2, 4, 5))
submit()
boring_function('My first function')
boring_function('My first function!')
boring_function
submit()
my_mean(c(4, 5, 10))
bye()
x <- sample(c(0,1),1000)
?sample
x <- sample(c(0,1),1,100)
x
x <- sample(c(0,1),n=1,size=100)
getwd()
directory <- "/Users/mitchellmurphy/DataScience/datasets/specdata/"
setwd(directory)
setwd(""/Users/mitchellmurphy/DataScience/datasets/specdata/"")
setwd("/Users/mitchellmurphy/DataScience/datasets/specdata/")
setwd("/Users/mitchellmurphy/DataScience/datasets/specdata/")
setwd("/Users/mitchellmurphy/Desktop/DataScience/datasets/specdat/")
dir()
rnorm(2*2*10)
c(2,2,10)
rm(rate, envir = .GlobalEnv)
?mapply
mapply(rep, 1:4, 4:1)
?noise
?gl
gl(4,10)
?tapply(vector, index, function)
?tapply
x <- gl(3,20)
head(x)
typeof(x)
levels(x)
split(x,levelsx)
split(x,levels(x))
library(datasets)
levels(airquality)
colnames(airquality)
head(airquality)
levels(airquality$Month)
?split
monthly <- split(airquality, airquality$Month)
monthly
typeof(airquality$Month)
lapply(monthly, mean)
View(monthly)
avg.temps <- lapply(monthly, function(x) { colMeans(x[,"Temp"]) })
avg.temps <- lapply(monthly, function(x) colMeans(x[,"Temp"]) )
lapply(monthly, function(x) colMeans(x[,"Temp"]))
lapply(monthly, function(x) colMeans(x[,c("Ozone", Temp")]))
lapply(monthly, function(x) colMeans(x[,c("Ozone", Temp"))]))
rm(x)
lapply(monthly, function(x) { return(colMeans(x[,"Temp"])) })
s <- monthly
s
lapply(s, function(x) colMeans(x[,c("Ozone", "Solar.R", "Wind")]))
lapply(s, function(x) colMeans(x[,c("Temp")]))
factor(airquality$Month)
lapply(s, function(x) colMeans(x[,c("Ozone", "Solar.R", "Wind")]))
lapply(s, function(x) colMeans(x[,c("Ozone", "Temp", "Wind")]))
head(monthly)
View(monthly)
lapply(s, function(x) colMeans(x[,c("Ozone", "Temp", "Wind")], na.rm = T))
rm(s)
sapply(monthly, function(x) colMeans(x[,"Temp"]))
sapply(monthly, function(x) colMeans(x[,"Ozone",Temp"]))
sapply(monthly, function(x) colMeans(x[,c("Ozone", "Temp")]))
sapply(monthly, function(x) colMeans(x[,c("Ozone", "Temp")]), na.rm = T)
sapply(monthly, function(x) colMeans(x[,c("Ozone", "Temp")], na.rm = T))
sapply(monthly, function(x) colMeans(x))
sapply(monthly, function(x) colMeans(x, na.rm = T))
?interaction
f1 <- gl(2,5)
f2 <- gl(5,2)
interaction(f1,f2)
log(-1)
log(Inf)
log(0)
traceback()
x <- rnorm(100])
x <- rnorm(100)
y <- rnorm(100)
mf <- model.frame(y~x)
mf
mdl <- lm(y~x)
summary(mdl)
?predict
?eval
x2 <- rnorm(10)
predict(mdl, newdata = x2)
predict(mdl,x2)
data("iris")
data(iris)
head(iris)
View(iris)
?split
mean(iris[iris$Species == "virginica"])
mean(iris[iris$Species == "virginica",'Sepal.Length'])
split(iris, iris$Species)
sapply(split(iris, iris$Species), mean)
iris.species <- split(iris, iris$Species)
View(iris.species)
mean(iris.species$virginica)
mean(iris.species$virginica[,"Sepal.Width"])
mean(iris.species$virginica[,"Sepal.Length"])
apply(iris[, 1:4], 1, mean)
head(iris[,1:4])
?apply
library(datasets)
data("mtcars")
head(mtcars)
tapply(mtcars$mpg, mtcars$cyl, mean)
?tapply(vector, index, function)
?tapply
apply(mtcars, 2, mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
lapply(mtcars, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
mean(mtcars$mpg, mtcars$cyl)
sapply(mtcars, cyl, mean)
tapply(mtcars$hp, mtcars$cyl, mean)
122.28571-82.63636
debug(ls)
ls()
?with
with(mtcars, tapply(hp, cyl, mean))
209.21429-82.63636
rm(rate)
library(datasets)
data(iris)
head(iris)
?sapply
sapply(split(iris$Sepal.Length, iris$Species), mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
sapply(split(mtcars$hp, mtcars$cyl), mean)
209.21429-82.63636
?grep
?solve
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
cachemean <- function(x, ...) {
m <- x$getmean()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
makeCacheMatrix <- function(m = matrix()) {
inv <- NULL #placeholder for inverse
get <- function() m
set <- function(mat) {
m <<- mat
i <<- NULL
}
# also need getter and setter for inv
getInverse <- function() inv
setInverse <- function(i) {
inv <<- i
}
# return list of all 4 of these properties
list(get = get, set = set, getInverse = getInverse, setInverse = setInverse)
}
cacheSolve <- function(x, ...) {
inv <- x$getInverse()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
inv <- solve(data)
x$setInverse(inv)
inv
}
x <- seq(0,1,100)
head(x)
?seq
x <- seq(from =0, to = 1, by = 0.01)
head(x)
?log
y <- log10(x)
head(y)
tail(y)
y <- log(x)
head(y)
tail(y)
head(log2(x))
head(log(x))
log1p(0)
log(1)
log1p(1)
log(2)
?lag
install.packages("RMySQL")
library(RMySQL)
ucscDb <- dbConnect(MySQL(),user = "genome", host = "genome-mysql.soe.ucsc.edu")
result <- dbGetQuery(ucscDb, "show databases;"); dbDisconnect(ucscDb);
result
typeof(result)
typeof(ucscDb)
dbUser <- "genome"
dbHost <- "genome-mysql.soe.ucsc.edu"
hg19 <- dbConnect(MySQL(), user =dbUser, db = "hg19", host = dbHost)
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
typeof(allTables)
dbListFields(hg19, "HInv")
dbListFields(hg19, allTables[1])
allTables[1:100]
dbListFields(hg19, "affyU133Plus2")
dbGetQuery(hg19, "select count(*) affyU133Plus2")
dbGetQuery(hg19, "select count(*) affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
affyData <- dbReadTable(hg19, "affyU133Plus2")
head(affyData)
data <- dbGetQuery(hg19, "select * from affyU133Plus2")
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatch between 1 and 3")
head(data)
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
type.convert(query)
typeof(query)
affyMis <- fetch(query); quantile(affyMis$misMatches)
head(affyMis)
dim(affyMis)
affyMisSmall <- fetch(query, n=10); dbClearResult(query);
dim(affyMisSmall)
query
dbDisconnect(hg19)
source("https://bioconductor.org/biocLite.R")
source("https://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
created = h5createFile("example.h5")
created
typeof(created)
dir()
if(created) {
createdGroup1 <- h5createGroup("example.h5", "foo")
createdGroup2 <- h5createGroup("example.h5", "bar")
if(createdGroup1) {
createdGroup3 <- h5createGroup("example.h5", "foo/foobar")
}
}
h5ls("example.h5")
install.packages(c("jpeg", "png", "bmp"))
library(jpeg)
img <- readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
img <- readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", "jeff.jpg")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", "jeff.jpg", mode = "wb")
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
, 'jeff.jpg'
, mode='wb' )
img <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
img <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", "jeff.jpg")
library(data.table)
dt <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
dt <- data.table(dt)
head(dt)
dt <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
head(dt)
dt <- data.table(dt)
GDP <- dt
rm(dt)
ed <- data.table::fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv")
EDU <- data.table::fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv")
GDP <- fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
rm(ed)
rm(img)
rm(rate)
cameraData <- fread("https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD")
View(cameraData)
tolower(names(cameraData))
names(cameraData)
names(cameraData) <- tolower(names(cameraData))
names(cameraData)
splitNames <- strsplit(names(cameraData), "\\.")
splitNames
splitNames[[6]]
splitNames[[6]][[1]]
firstElement <- function(x) { x[1] }
sapply(splitNames, firstElement)
reviews <- read.csv("https://github.com/jtleek/dataanalysis/blob/master/week2/007summarizingData/data/reviews.csv")
solutions <- read.csv("https://github.com/jtleek/dataanalysis/blob/master/week2/007summarizingData/data/solutions.csv")
?sub
sub("_", "", names(reviews),)
View(reviews)
reviews <- read.csv("https://raw.githubusercontent.com/jtleek/dataanalysis/master/week2/007summarizingData/data/reviews.csv")
reviews <- read.csv("https://raw.githubusercontent.com/jtleek/dataanalysis/master/week2/007summarizingData/data/reviews.csv")
solutions <- read.csv("https://raw.githubusercontent.com/jtleek/dataanalysis/master/week2/007summarizingData/data/solutions.csv")
names(reviews)
sub("_","", names(reviews))
names(reviews)
names(reviews) <- sub("_","", names(reviews))
names(reviews)
length("This is a test")
paste("Mitch", "Murphy")
paste("Mitch", "Murphy", sep = " ")
paste0("Mitch", "Murphy")
paste("Mitch", "Murphy", sep = "")
?date
Sys.Date()
Sys.setenv(TZ = "America/New_York")
Sys.getenv("TZ")
as.POSIXct(t, tz=getOption("tz"))
Sys.Date()
Sys.Date()
?format
dte <- format(Sys.Date(), "%m/%d/%Y")
dte
date2 <- as.Date("02/11/2018")
date2
date2 - dte
class(dte)
class(date2)
date2 <- format("02/11/2018", "%m/%d/%Y")
format(Sys.Date(), "%m/%d/%Y")
format(Sys.Date(), "%m/%d/%Y") + 14
julian(dte)
julian(Sys.time())
library(data.table)
ACS <- fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
View(ACS)
names(ACS)
init <- function(base_directory = "~/Desktop/DataScience/coursera/") {
# Set the working directory
setwd(base_directory)
# Load needed packages
library(data.table)
library(reshape2)
}
## This function will read in both the train and test sets
## and cleans it up so we just have a train and test data.tables
## Not split into 2 functions due to how I use lexical scoping
readAndCleanData <- function() {
# "/Users/mitchellmurphy/Desktop/DataScience/coursera/data/UCI_HAR_Dataset/"
dataDirectory <- paste(getwd(),"data/UCI_HAR_Dataset/",sep = "/")
# Read data
activityLabels <<- fread(paste0(dataDirectory, "activity_labels.txt"), col.names = c("classLabels", "activityName"))
features <- fread(paste0(dataDirectory, "features.txt"), col.names = c("index", "featureNames"))
featuresToInclude <- grep("(mean|std)\\(\\)", features[, featureNames])
measurements <- features[featuresToInclude,featureNames]
measurements <- gsub('[()]', '', measurements)
train.x <- fread(paste0(dataDirectory,"train/X_train.txt"))[, featuresToInclude, with = FALSE]
data.table::setnames(train.x, colnames(train.x), measurements)
train.y <- fread(paste0(dataDirectory,"train/Y_train.txt"), col.names = c("Activity"))
train.subjects <- fread(paste0(dataDirectory,"train/subject_train.txt"), col.names = c("SubjectNum"))
train <<- cbind(train.subjects, train.y, train.x)
# Now load up the test data
test.x <- fread(paste0(dataDirectory,"test/X_test.txt"))[, featuresToInclude, with = FALSE]
data.table::setnames(test.x, colnames(test.x), measurements)
test.y <- fread(paste0(dataDirectory,"test/Y_test.txt"), col.names = c("Activity"))
test.subjects <- fread(paste0(dataDirectory,"test/subject_test.txt"), col.names = c("SubjectNum"))
test <<- cbind(test.subjects, test.y, test.x)
}
init()
# this function will do most of the work for us (reading and cleaning up the data)
readAndCleanData()
## Merges the training and the test sets to create one data set.
if(is.null(train) & is.null(test)) {
stop("train and test variables do not exist. Make sure you first call readAndClean()")
}
total <- rbind(train, test)
## Coerce the SubjectNum column into factors
total$SubjectNum <- as.factor(total$SubjectNum)
# Now let us map the Activity number into its equiv name (read from activities.txt) in activitesLabel list
total$Activity <- factor(total$Activity, levels = activityLabels[["classLabels"]], labels = activityLabels[["activityName"]])
## From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject
## This will be our final, "tidy" data set
total <- reshape2::melt(data = total, id = c("SubjectNum", "Activity"))
total <- reshape2::dcast(data = total, SubjectNum + Activity ~ variable, fun.aggregate = mean)
dir()
write.table(total, file = "total.txt")
library(data.table)
?install.packages
install.packages("data.table", type = "mac.binary")
install.packages("data.table", type = "mac.binary")
library(data.table)
## Now save (write) this data table to disk
write.table(total, file = "data/tidyData.txt")
colnames(total)
write.csv(colnames(total), file = "feats.csv")
write.csv(activityLabels, file = "activ.csv")
feats <- colnames(total)
head(feats)
typeof(feats)
# first check if the data is already there. If not, download it
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile = "data/UCI HAR Dataset.zip")
getwd()
dataDirectory <- paste(getwd(), "data", sep = "/")
dataDirectory
dataDirectory <- paste(getwd(), "data/UCI HAR Dataset/", sep = "/")
dataDirectory
dir.exists("dataDirectory <- paste(getwd(), "data/UCI HAR Dataset/", sep = "/")")
dir.exists(dataDirectory)
?download.file
dataDirectory
dir.exists("/Users/mitchellmurphy/Desktop/DataScience/coursera/data/UCI HAR Dataset")
dir.exists("/Users/mitchellmurphy/Desktop/DataScience/coursera/data/UCI HAR Dataset2")
unzip(paste0(dataDirectory, ".zip"))
paste0(dataDirectory, ".zip")
dataDirectory <- paste(getwd(), "data/UCI HAR Dataset", sep = "/")
paste0(dataDirectory, ".zip")
unzip(paste0(dataDirectory, ".zip"))
init <- function(base_directory = "~/Desktop/DataScience/coursera/") {
# Set the working directory
setwd(base_directory)
# Load needed packages
library(data.table)
library(reshape2)
}
downloadData <- function() {
dataDirectory <- paste(getwd(), "data/UCI HAR Dataset", sep = "/")
if(!dir.exists(dataDirectory)) {
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile = "data/UCI HAR Dataset.zip")
unzip(paste0(dataDirectory, ".zip"))
}
# first check if the data is already there. If not, download it
}
## This function will read in both the train and test sets
## and cleans it up so we just have a train and test data.tables
## Not split into 2 functions due to how I use lexical scoping
readAndCleanData <- function() {
# "/Users/mitchellmurphy/Desktop/DataScience/coursera/data/UCI_HAR_Dataset/"
dataDirectory <- paste(getwd(),"data/UCI HAR Dataset/",sep = "/")
# Read data
activityLabels <<- fread(paste0(dataDirectory, "activity_labels.txt"), col.names = c("classLabels", "activityName"))
features <- fread(paste0(dataDirectory, "features.txt"), col.names = c("index", "featureNames"))
featuresToInclude <- grep("(mean|std)\\(\\)", features[, featureNames])
measurements <- features[featuresToInclude,featureNames]
measurements <- gsub('[()]', '', measurements)
train.x <- fread(paste0(dataDirectory,"train/X_train.txt"))[, featuresToInclude, with = FALSE]
data.table::setnames(train.x, colnames(train.x), measurements)
train.y <- fread(paste0(dataDirectory,"train/Y_train.txt"), col.names = c("Activity"))
train.subjects <- fread(paste0(dataDirectory,"train/subject_train.txt"), col.names = c("SubjectNum"))
train <<- cbind(train.subjects, train.y, train.x)
# Now load up the test data
test.x <- fread(paste0(dataDirectory,"test/X_test.txt"))[, featuresToInclude, with = FALSE]
data.table::setnames(test.x, colnames(test.x), measurements)
test.y <- fread(paste0(dataDirectory,"test/Y_test.txt"), col.names = c("Activity"))
test.subjects <- fread(paste0(dataDirectory,"test/subject_test.txt"), col.names = c("SubjectNum"))
test <<- cbind(test.subjects, test.y, test.x)
}
init()
# this function will do most of the work for us (reading and cleaning up the data)
downloadData()
readAndCleanData()
if(is.null(train) & is.null(test)) {
stop("train and test variables do not exist. Make sure you first call readAndClean()")
}
total <- rbind(train, test)
## Coerce the SubjectNum column into factors
total$SubjectNum <- as.factor(total$SubjectNum)
# Now let us map the Activity number into its equiv name (read from activities.txt) in activitesLabel list
total$Activity <- factor(total$Activity, levels = activityLabels[["classLabels"]], labels = activityLabels[["activityName"]])
## From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject
## This will be our final, "tidy" data set
total <- reshape2::melt(data = total, id = c("SubjectNum", "Activity"))
total <- reshape2::dcast(data = total, SubjectNum + Activity ~ variable, fun.aggregate = mean)
## Now save (write) this data table to disk
write.table(total, file = "data/tidyData.txt")
dataDirectory <<- paste(getwd(), "data/UCI HAR Dataset", sep = "/")
## Now save (write) this data table to disk
write.table(total, file = paste(dataDirectory, "tidyData.txt", sep = "/"))
dataDirectory
